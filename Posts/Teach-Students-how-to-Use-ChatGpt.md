---
tags:
- ai
- ethics
- chatgpt
menuorder: 0
id: 8ef8b660-1646-4b1b-91b8-e5cfdedad0b0
author: bsstahl
title: Teach Students how to Use ChatGPT
description: Students should not be prevented from using ChatGPT just as they shouldn't be prevented from using Wikipedia, spelling &amp; grammar checkers, and other productivity tools.
ispublished: true
showinlist: false
publicationdate: 2022-12-17T16:00:00.000+00:00
lastmodificationdate: 2022-12-17T16:00:00.000+00:00
slug: teach-students-how-to-use-chatgpt
categories:
- Tools
---
There have been a number of concerns raised, with clearly more to come, about the use of *ChatGPT* and similar tools in academic circles. I am not an academic, but I am a professional and I believe these concerns to be misplaced.

> As a professional in my field, I should and do use tools like *ChatGPT* to do my job.

I, and the teams I work with, experiment with ways to use tools like ChatGPT better. We use these tools to create the foundation for our written work. We use them to automate the mundane stuff. We use them as thinking tools, to prompt us with ideas we might not have considered. This is not only allowed, it is encouraged!

#### Why should it be different for students?

There are several good analogs for *ChatGPT* that we all have used for years, these include:

1. The predictive text on our mobile phones - It is the same as pressing the middle word on the virtual keyboard to autocomplete a sentence. That is all this tool does, predict what is the most likely next word based on the inputs.

2. The template in your chosen word processing software (i.e. MS Word or Google Docs) - Both will create a framework for you where you fill in the details. This is really all that *ChatGPT* does, it just does it in a more visually impressive way.

3. Grammar and Thesaurus Software - "Suggests" words that can be modified to make the meaning clearer or the language more traditionally appropriate.

4. Wikipedia, or other information aggregator - A source of text that can be used as a starting point for research, or a source of plagiarized material, at the discretion of the user.

Nobody thinks twice about using any of these tools anymore, though there was certainly concern early-on about Wikipedia. This is probably due to reasons like these:

1. If anyone, student or professional, produced a work product that was just an unmodified template, it would considered very sloppy and incomplete work, and would be judged as such on its merits.

2. If anyone, student or professional, produced a work product that was copied from Wikipedia or other source, without significant modification or citation, there would be clear evidence of that fact available via the Internet.

*ChatGPT* is concerning to academics because it has become good enough at doing the work of these template and predictive tools to pass a higher standard of review, and its use cannot be proven, only given a probability score. However, like all tools, the key is not **that** it is used, but **how** it is used.

The text that *ChatGPT* produces is generated probabilistically. It is not enough just to have it spit out a template and submit it as work product. Its facts need to be verified (and are often wrong). Its "analysis" needs to be tested and verified. Its "writing" needs to be clarified and organized. When you submit work where *ChatGPT* was used to automate the mundane task of generating the basic layout, you are saying that you have verified the text and that you stand behind it. It is your work and you are approving it. **If it has lied, you have lied. If the words it spit-out result in a bad analysis, it is your bad analysis**. The words are yours when you submit them regardless of whether they were generated via the neural network of your brain, the artificial neural network of *ChatGPT*, or some other, perhaps procedural method.

I'll say it clearly for emphasis:

> All work should be judged on its merits

#### Educators should teach how to use these tools responsibly and safely

Academics and professionals alike, please do not attempt to legislate the use of these tools. Instead, focus on how they **should be used**. Teach ethical and safe usage of these tools in a similar way to how we teach students to use Wikipedia. These productivity aids are not going away, they are only going to get better. We need to show everyone how to use them to their advantage, and to the advantage of their teams and of society.

My field of *Software Engineering* is primarily about solving problems. To solve problems, we describe solutions to these problems in ways that are easy for a machine to interpret. The only difference between the code I write that goes into a *compiler* to be turned into machine-executable instructions, and the code I write to go into *ChatGPT* is the language that I use to describe my intent. Using *ChatGPT* is just writing a computer program using the English language rather than *C#* or *Python*. A process such as that should absolutely be encouraged whether the usage is academic or not.

It is my firm belief that the handwringing about the productivity gains that a fantastic tool like ChatGPT can give us is not only misplaced, it is often dangerously misleading.

#### Addendum

I am only now realizing I should have used ChatGPT to produce the foundations of this text. A missed opportunity to be certain, though to be fair, I originally intended this to be a one or two liner, not an essay.

#### Disclosure

I have no stake whatsoever in ChatGPT except as a beta user.
