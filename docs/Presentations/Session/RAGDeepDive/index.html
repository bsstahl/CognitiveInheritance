<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>The Future of Information Retrieval</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/carvana.css">
    <link rel="stylesheet" href="css/headers.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
</head>
<body>
    <div class="reveal">
        <div class="slides">
            <section data-transition="slide-in slide-out" data-background='img/19ae31f8-078b-4bd3-8411-0222b6a09c25.jpg'>
<a id="ee062bcb-426b-49d3-8e8a-2d0e005245d0">&nbsp;</a>
<!-- Layout:ImageRight -->
<!-- ContentItem:8ac9d5ff-1136-4d99-8448-de49bd005889 -->
<!-- ContentItem:685060d8-4205-4db9-b44d-9610a7729e7d -->

<table><tr><td style="vertical-align:top;">
<h1 id="the-future-of-information-retrieval">The Future of Information Retrieval</h1>
<h2 id="a-deep-dive-into-rag">A Deep Dive into RAG</h2>
<hr />
<h3 id="barry-s.stahl">Barry S. Stahl</h3>
<h3 id="solution-architect-developer">Solution Architect &amp; Developer</h3>
<h3 id="bsstahlcognitiveinheritance.com"><a href="https://fosstodon.org/@Bsstahl">@bsstahl@cognitiveinheritance.com</a></h3>
<h3 id="httpscognitiveinheritance.com"><a href="https://cognitiveinheritance.com">https://CognitiveInheritance.com</a></h3>

</td>
<td style="text-align: left;">
<img src="img/685060d8-4205-4db9-b44d-9610a7729e7d.png" alt="Transparent Half Width Image 720x800.png" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="636059f9-aa9d-4444-b4ec-dd7f62badd98"><h1>Favorite Physicists & Mathematicians</h1></a>
<!-- Layout:MultiColumn -->
<!-- ContentItem:30f7e9d2-b154-4895-bed7-2765f7bdc6fe -->
<!-- ContentItem:8a83be06-76e9-4028-9630-c6a7de92ae99 -->
<aside class="notes"><p>An up-to-date list is available on <a href="https://cognitiveinheritance.com/Pages/Favorites.html">my blog at https://cognitiveinheritance.com/Pages/Favorites.html</a>
Please ping me on Mastodon to tell me where I messed-up with this list, or this presentation for that matter. ðŸ˜‰</p>
</aside>
<table><tr><td style="vertical-align:top;">
<h4 id="favorite-physicists">Favorite Physicists</h4>
<ol>
<li>Harold &quot;Hal&quot; Stahl</li>
<li>Carl Sagan</li>
<li>Richard Feynman</li>
<li>Marie Curie</li>
<li>Nikola Tesla</li>
<li>Albert Einstein</li>
<li>Neil Degrasse Tyson</li>
<li>Niels Bohr</li>
<li>Galileo Galilei</li>
<li>Michael Faraday</li>
</ol>
<p><em>Other notables</em>: Stephen Hawking, Edwin Hubble</p>

</td>
<td style="vertical-align:top;">
<h4 id="favorite-mathematicians">Favorite Mathematicians</h4>
<ol>
<li>Ada Lovelace</li>
<li>Alan Turing</li>
<li>Johannes Kepler</li>
<li>Rene Descartes</li>
<li>Isaac Newton</li>
<li>Emmy Noether</li>
<li>George Boole</li>
<li>Blaise Pascal</li>
<li>Johann Gauss</li>
<li>Grace Hopper</li>
</ol>
<p><em>Other notables</em>: Daphne Koller, Grady Booch, Leonardo Fibonacci, Evelyn Berezin, Benoit Mandelbrot</p>

</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<aside class="notes"><p>Liquid Victor was used to create this slide deck</p>
</aside>
<a id="23528a73-7bc1-4e39-9f2f-c8b9e2cff982"><h1>Some OSS Projects I Run</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:f8cbcb81-15f7-48e0-bc29-b348732f6f05 -->
<ol>
<li><a href="https://github.com/bsstahl/liquidvictor">Liquid Victor</a> : Media tracking and aggregation [used to assemble this presentation]</li>
<li><a href="https://github.com/bsstahl/pptail">Prehensile Pony-Tail</a> : A static site generator built in c#</li>
<li><a href="https://github.com/bsstahl/testhelperextensions">TestHelperExtensions</a> : A set of extension methods helpful when building unit tests</li>
<li><a href="https://github.com/bsstahl/conferencescheduler">Conference Scheduler</a> : A conference schedule optimizer</li>
<li><a href="https://github.com/bsstahl/intentbot">IntentBot</a> : A microservices framework for creating conversational bots on top of Bot Framework</li>
<li><a href="https://github.com/bsstahl/liquidnun">LiquidNun</a> : Library of abstractions and implementations for loosely-coupled applications</li>
<li><a href="https://github.com/bsstahl/toastmastersagenda">Toastmasters Agenda</a> : A c# library and website for generating agenda's for Toastmasters meetings</li>
<li><a href="https://github.com/bsstahl/PDM">ProtoBuf Data Mapper</a> : A c# library for mapping and transforming ProtoBuf messages</li>
</ol>

</section>


<section data-transition="slide-in slide-out">
<aside class="notes"><p>I am proud to be one of the founders of AZGiveCamp.
GiveCamps are weekend events where we put a bunch of software creators in a room with a bunch of great local charities, and through the course of the weekend, we create software to help them further their mission</p>
</aside>
<a id="3129a405-82a7-432c-ae55-6f9d2335ab17"><h1>http://GiveCamp.org</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:2ca346de-d62c-4c6b-834d-7ccab290a6ab -->
<img alt="GiveCamp.png" src="img/2ca346de-d62c-4c6b-834d-7ccab290a6ab.png" />
</section>


<section data-transition="slide-in slide-out">
<aside class="notes"><p>July 25, 2022 was my 100th public talk. Thank you for allowing me to participate in your community over these past few decades!</p>
</aside>
<a id="39c6410c-3913-410b-abab-984014a15d84"><h1>Achievement Unlocked</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:a042b106-4bab-4403-b5b6-0d7b414ef789 -->
<img alt="bss-100-achievement-unlocked-1024x250.png" src="img/a042b106-4bab-4403-b5b6-0d7b414ef789.png" />
</section>


<section data-transition="slide-in slide-out" data-background='img/23075294-3e2f-4352-8a16-9080139eab75.png'>
<aside class="notes"><p>To start with, let's look a a traditional keyword search, then see how that presents using more-modern methods</p>
</aside>
<a id="abdbcca9-568e-43c5-95bb-9932e51994be">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out" data-background='img/4b375b32-043a-4bb6-97a7-15c641e79175.png'>
<aside class="notes"><p>The same search query performed using an Embeddings based vector search. The results are much  more relevant than with keywords because the context of each word  is better &quot;understood&quot; by the model.</p>
</aside>
<a id="10650fc2-1bfa-4f5b-a305-c19fa95efd86">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out" data-background='img/598de942-8d93-47cc-a5e4-69a1b7064353.png'>
<aside class="notes"><p>Using an LLM, the same search results produced an actual answer rather than just  a list of documents that might be relevant. The question then becomes, is this  answer correct?</p>
</aside>
<a id="242d0812-764c-4a2f-8b7c-61ec5c4514da">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out" data-background='img/669ba222-afb5-4826-9dd4-916d99a0910a.png'>
<aside class="notes"><p>The answer also comes with a list of references, the same documents returned by the vector search. This can help us determine if the answer is correct, or at least as correct as   the documents themselves.</p>
</aside>
<a id="e741ef19-86d7-4461-af1d-23c4407b9705">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out">
<a id="1ea94cc1-73c2-448c-9853-0029065899f3"><h1>Keyword Search</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:81298dd1-0dd5-4d22-bbbb-5ac12dbe3c7d -->
<!-- ContentItem:5d62a9ac-151b-4110-8371-5f10f4f1440f -->
<aside class="notes"><p>Keyword Search produces inferior results to Vector Search,  because it throws-away important context.</p>
<ul>
<li>Removing Stop words eliminates context i.e.  &quot;looking place stay new york&quot; matches places to find jobs,  sights, relationships, etc during a stay in NY.</li>
<li>Stemming removes context: <em>running a program</em>  might return docs on <em>10k runs</em>.</li>
</ul>
<p>An Index is &quot;Inverted&quot; when it starts with words and lists documents instead of  starting with a document and listing words</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li><p>Tokenization</p>
<ul>
<li>Break into lower-case tokens</li>
<li><strong>best</strong>,<strong>ways</strong>,<strong>to</strong>,<strong>learn</strong>,<strong>about</strong>,<strong>my</strong>,<strong>problem</strong>,<strong>domain</strong></li>
</ul>
</li>
<li><p>Remove Stop Words</p>
<ul>
<li>Words like &quot;to,&quot; &quot;about,&quot; and &quot;my&quot; are removed</li>
<li><strong>best</strong>,<strong>ways</strong>,<strong>learn</strong>,<strong>problem</strong>,<strong>domain</strong></li>
</ul>
</li>
<li><p>Stemming/Lemmatization</p>
<ul>
<li>Reduce tokens to their root form</li>
<li>No changes are required to this query</li>
<li>Examples: &quot;runner&quot; =&gt; &quot;run&quot;, &quot;children&quot; =&gt; &quot;child&quot;</li>
</ul>
</li>
<li><p>Inverted Index Lookup:</p>
<ul>
<li>Find matching documents</li>
<li>Sort descending by Relevance Score</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/5d62a9ac-151b-4110-8371-5f10f4f1440f.jpg" alt="Card Catalog 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<aside class="notes"><ul>
<li>Before 2013, all innovation was about adding context to keyword searches.
<ul>
<li>i.e. <strong>BM25</strong>, which ranks documents based on term frequency, inverse document frequency, and
document length normalization.</li>
</ul>
</li>
<li><strong>word2vec</strong> (2013) introduced us to using mathematical representations of words and concepts</li>
<li><strong>Attention is all you Need</strong> (2017) kicked-off the LLM revolution</li>
<li>By 2022, nearly all search mechanisms are using some form of Vector search</li>
</ul>
</aside>
<a id="2179bff6-ac81-4818-9da4-261f65279a0a"><h1>Evolution of Search Tech</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:756413f9-4e34-408a-9c28-93704ecd07ab -->
<img alt="Timeline-Evolution of Search Tech.png" src="img/756413f9-4e34-408a-9c28-93704ecd07ab.png" />
</section>


<section data-transition="slide-in slide-out">
<a id="300adcbd-5473-464b-85e0-25b86f0d40bf"><h1>Questions to be Answered</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:00dda57f-1c9c-45b0-87da-8a778f899496 -->
<!-- ContentItem:a3655477-bc7d-4526-ab36-9129ed7967a0 -->

<table><tr><td style="vertical-align:top;">
<ul>
<li>What are Embeddings?</li>
<li>How does Vector Search leverage Embeddings to find relevant info?</li>
<li>How does RAG build on top of Vector Search?</li>
<li>How do we overcome the limitations of these models?</li>
<li>How do we leverage these tools for the benefit of our Users?</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/a3655477-bc7d-4526-ab36-9129ed7967a0.jpg" alt="Questions to be Answered 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="54851746-90a1-45fa-980d-9cdcc12953cc"><h1>Embeddings</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:8c297a4c-5130-4206-ae37-995649e7d962 -->
<!-- ContentItem:0e0658fb-5565-43c7-a9fc-3de3155352f3 -->
<aside class="notes"><p>There are many other embedding models, some are optimized for different purposes. You should consider what model might work best for your use-case. This presentation uses the same model used by GPT-3 and GPT-4.</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>A point in multi-dimensional space</li>
<li>Mathematical representation of a word or phrase</li>
<li>Encode both <strong>semantic</strong> and <strong>contextual</strong> information</li>
</ul>
<hr />
<ul>
<li>Model: <code>text-embedding-ada-002</code></li>
<li>Vectors normalized to unit length</li>
<li>Use 1536 dimensions</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/0e0658fb-5565-43c7-a9fc-3de3155352f3.jpg" alt="Embeddings - Cosmic Desert 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in none-out">
<aside class="notes"><p>I used a T-SNE (T-distributed Stochastic Neighbor Embedding) transformation to perform this dimensionality reduction</p>
</aside>
<a id="9ec34ef5-afab-43e9-abf1-010e746b7af4">&nbsp;</a>
<!-- Layout:FullPage -->
<!-- ContentItem:2313fe54-9904-4e1c-b5de-3c29c297fdc7 -->
<img alt="Ram - Just Statements.png" src="img/2313fe54-9904-4e1c-b5de-3c29c297fdc7.png" />
</section>


<section data-transition="none-in slide-out">
<aside class="notes"><p>The key to understanding embeddings is to remember that they are a way to represent a word or phrase in a multi-dimensional space.  The distance between two embeddings can be used to determine how similar the words or phrases they represent are to each other.</p>
</aside>
<a id="3714c934-4902-45a1-9948-3b31c7f02bba">&nbsp;</a>
<!-- Layout:FullPage -->
<!-- ContentItem:43926256-864d-4a0a-aad0-b7ea6fa5b74e -->
<img alt="Ram - With Clusters.png" src="img/43926256-864d-4a0a-aad0-b7ea6fa5b74e.png" />
</section>


<section data-transition="slide-in slide-out">
<a id="2a4404ba-5f58-4efc-a214-b720b27105d7"><h1>Embedding</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:4e98361e-c44b-4fb0-b524-808cf99d9dbc -->
<!-- ContentItem:eca91cad-0f7d-40f9-a474-151b769223d1 -->

<table><tr><td style="vertical-align:top;">
<blockquote>
<p>Creating Order from Chaos</p>
</blockquote>
<ul>
<li>Unstructured <code>string</code> =&gt; Structured <code>float[]</code></li>
<li>Allows mathematical operations
<ul>
<li>Cosine Similarity &amp; Distance</li>
<li>Nearest Neighbor Search</li>
<li>Clustering</li>
<li>Vector Addition &amp; Subtraction</li>
<li>Dimensionality Reduction (e.g., PCA)</li>
<li>Anomaly Detection</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/eca91cad-0f7d-40f9-a474-151b769223d1.jpg" alt="Order from Chaos 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="05fbe145-6ed0-419c-aec9-1ccf634854b2"><h1>LM Studio</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:58300355-6876-465b-9d6d-cd37ad322b96 -->
<!-- ContentItem:73837f99-a36b-4270-8926-41e651161762 -->

<table><tr><td style="vertical-align:top;">
<ul>
<li>Interface to language &amp; embedding models</li>
<li>Fine-tune, evaluate, and integrate models into apps</li>
<li>Local server for testing models and applications</li>
<li>Models can be downloaded from <a href="https://huggingface.co/models">HuggingFace</a></li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/73837f99-a36b-4270-8926-41e651161762.png" alt="LMStudio - Features 800x800.png" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out" data-background='img/8dd40c19-2389-43aa-8b95-b0cfa03d8d8b.png'>

<a id="0b786f57-ef49-4f6a-8e68-21ba7ebd117e">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out" data-background='img/071045c7-5518-46cf-b8db-24b23fc85cf9.png'>

<a id="438dd1ec-3ab9-490d-860c-d27329156303">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out" data-background='img/d2760bb9-f64a-4ae9-b351-165882d85076.png'>

<a id="f101f2e7-8c01-402e-91e1-85e9aa128ed6">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out" data-background='img/7d6f9c87-cc7c-4cf8-840a-8fc9a70550d1.png'>

<a id="2396f909-6cb5-495e-91ca-4db9c6c65a4c">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out">
<a id="1390e720-0103-4d3b-8282-2eeb7f3be60b"><h1>Embedding Services</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:bd7c7347-347e-43d3-9e67-5f923ced0d7e -->
<!-- ContentItem:ca2f277b-647d-4526-acd6-9015061bf92c -->

<table><tr><td style="vertical-align:top;">
<ul>
<li><p>Local Models</p>
<ol>
<li><p>Load Model in LM Studio</p>
</li>
<li><p>Start Local Inference Server</p>
</li>
<li><p>Issue HTTP request for embedding</p>
</li>
<li><p>Retrieve embedding from response</p>
</li>
</ol>
</li>
<li><p>Remote Models</p>
<ol>
<li><p>Deploy model API</p>
</li>
<li><p>Issue HTTP request for embedding</p>
</li>
<li><p>Retrieve embedding from response</p>
</li>
</ol>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/ca2f277b-647d-4526-acd6-9015061bf92c.png" alt="Postman - Get Embedding from Local Model.png" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="72e0090e-a40f-4410-91e0-919b3ed09004"><h1>Cosine Similarity &amp; Distance</h1></a>
<!-- Layout:MultiColumn -->
<!-- ContentItem:89b66910-a26e-4116-b41d-3ada3f74c92b -->
<!-- ContentItem:d44bda2e-06bd-4064-9c06-12d564a6f5cf -->
<aside class="notes"><p>Since GPT vectors are normalized to unit length, Cosine similarity and dot-product calculations will produce the same result.</p>
</aside>
<table><tr><td style="vertical-align:top;">
<blockquote>
<p>Relate vectors based on the angle between them</p>
</blockquote>
<ul>
<li><p><em>Cosine Similarity</em> ranges from -1 to 1, where:</p>
<ul>
<li>+1 indicates that the vectors represent similar semantics &amp; context</li>
<li>0 indicates that the vectors are orthogonal (no similarity)</li>
<li>-1 indicates that the vectors have opposing semantics &amp; context</li>
</ul>
</li>
<li><p><em>Cosine Distance</em> is defined as <strong>1 - cosine similarity</strong> where:</p>
<ul>
<li>0 = Synonymous</li>
<li>1 = Orthogonal</li>
<li>2 = Antonymous</li>
</ul>
</li>
</ul>
<p>Note: For normalized vectors, cosine similarity is the same as the dot-product</p>

</td>
<td style="vertical-align:top;">
<img alt="Cosine Unit Circle - Enhanced.jpg" src="img/d44bda2e-06bd-4064-9c06-12d564a6f5cf.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">

<a id="0e2a1080-2694-447d-85ec-30f6863051de"><h1>Cosine Distance</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:1c9aab67-70df-45a0-b05d-4aae3c3a20c5 -->
<img alt="Cosine Distance 989x600.png" src="img/1c9aab67-70df-45a0-b05d-4aae3c3a20c5.png" />
</section>


<section data-transition="slide-in slide-out">
<aside class="notes"><p>I added additional context here: i.e. &quot;Sheep&quot; =&gt; &quot;Bighorn Sheep&quot;, to make the distances more visible.</p>
</aside>
<a id="952e53c0-3883-490e-a43f-c3f86853fc08"><h1>Cosine Distance</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:b079c831-8d8c-425b-8e49-c8674d0b3ec6 -->
<img alt="Angles2.svg" src="img/b079c831-8d8c-425b-8e49-c8674d0b3ec6.svg" />
</section>


<section data-transition="slide-in slide-out">
<aside class="notes"><p>Embeddings encode many facets of a word or phrase, including language spoken, idioms, sarcasm, and figurative language</p>
</aside>
<a id="b1b27a07-42ee-481c-92f4-6791f7204828"><h1>Embedding Distance</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:fcee17b4-8b97-487e-9644-0c45033c1ff3 -->
<table>
<thead>
<tr>
<th>Feature</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Synonym</td>
<td>&quot;Happy&quot; is closer to &quot;Joyful&quot; than to &quot;Sad&quot;</td>
</tr>
<tr>
<td>Language</td>
<td>&quot;The Queen&quot; is very close to &quot;La Reina&quot;</td>
</tr>
<tr>
<td>Idiom</td>
<td>&quot;He kicked the bucket&quot; is closer to &quot;He died&quot; than to &quot;He kicked the ball&quot;</td>
</tr>
<tr>
<td>Sarcasm</td>
<td>&quot;Well, look who's on time&quot; is closer to &quot;Actually Late&quot; than &quot;Actually Early&quot;</td>
</tr>
<tr>
<td>Homonym</td>
<td>&quot;Bark&quot; (dog sound) is closer to &quot;Howl&quot; than to &quot;Bark&quot; (tree layer)</td>
</tr>
<tr>
<td>Collocation</td>
<td>&quot;Fast food&quot; is closer to &quot;Junk food&quot; than to &quot;Fast car&quot;</td>
</tr>
<tr>
<td>Proverb</td>
<td>&quot;The early bird catches the worm&quot; is closer to &quot;Success comes to those who prepare well and put in effort&quot; than to &quot;A bird in the hand is worth two in the bush&quot;</td>
</tr>
<tr>
<td>Metaphor</td>
<td>&quot;Time is money&quot; is closer to &quot;Don't waste your time&quot; than to &quot;Time flies&quot;</td>
</tr>
<tr>
<td>Simile</td>
<td>&quot;He is as brave as a lion&quot; is closer to &quot;He is very courageous&quot; than to &quot;He is a lion&quot;</td>
</tr>
</tbody>
</table>

</section>


<section data-transition="slide-in slide-out">
<a id="295f37ae-5979-40ae-a5d9-a22bd58ef30a"><h1>Vector Databases</h1></a>
<!-- Layout:MultiColumn -->
<!-- ContentItem:fd61eed6-fd5e-4ce2-b9c9-f4c06f5287ff -->
<!-- ContentItem:7a67ae3f-567b-4099-b9ea-a2c2fb484d7f -->
<aside class="notes"><p>The key to operational use of Embeddings is some form of Vector data store,  whether that is persistent or in-memory.</p>
<p><strong>Azure AI Search</strong> was formerly known as <strong>Azure Cognitive Search</strong>.</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>Store/retrieve high-dimensional vectors</li>
<li>Values are retrieved using similarity searches</li>
<li>Leverage data-structures such as K-D Trees</li>
<li>Examples
<ul>
<li>Azure AI Search</li>
<li>Redis</li>
<li>Qdrant</li>
<li>Pinecone</li>
<li>Chroma</li>
</ul>
</li>
</ul>

</td>
<td style="vertical-align:top;">
<img alt="VectorDB-650x650.png" src="img/7a67ae3f-567b-4099-b9ea-a2c2fb484d7f.png" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="fcad5e62-f63e-45e4-b527-a12751208862"><h1>KD-Tree</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:1f451aee-70a3-497a-b53c-3ba95f17f453 -->
<!-- ContentItem:5c63c605-c602-4d5c-ac81-27501112174e -->

<table><tr><td style="vertical-align:top;">
<ul>
<li>&quot;Binary&quot; Search across K-Dimensions
<ul>
<li>O(n log n) for construction</li>
<li>O(log n) for search</li>
</ul>
</li>
<li>Construction
<ul>
<li>Recursively partitioning dataset</li>
<li>Rotate the dimension for each depth level</li>
</ul>
</li>
<li>Nearest Neighbor Search
<ul>
<li>Recursively search for nearest neighbor</li>
<li>Backtrack to find additional neighbors</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/5c63c605-c602-4d5c-ac81-27501112174e.jpg" alt="KD-Tree 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="7cd31e00-ffff-4f26-8321-2c9f8ccc1c93"><h1>Vector Search</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:533c8d05-697a-47d2-9ca0-366ab843a788 -->
<!-- ContentItem:6f12ef80-a7a5-4ca3-84ac-28d3c2b494e7 -->
<aside class="notes"><p>Vector search alone may not be enough to provide accurate results since <strong>Attention</strong> is not involved.
Let's look at an example of what this means.</p>
</aside>
<table><tr><td style="vertical-align:top;">
<blockquote>
<p>Vector Search: critical to modern information retrieval systems</p>
</blockquote>
<ul>
<li>Find the closest vectors to a query vector
<ul>
<li>Identifies Embeddings that are semantically similar to the query</li>
<li>Requires the same embedding model for query and search vectors</li>
</ul>
</li>
<li>Works with nearly any type of data
<ul>
<li>Images, text, audio, etc.</li>
<li>Requires an encoding model for each type</li>
</ul>
</li>
<li>Still a stochastic process
<ul>
<li>Results <em>may</em> vary between executions</li>
<li>Results <em>will</em> vary between encoding models</li>
<li>May produce <em>unexpected</em> results</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/6f12ef80-a7a5-4ca3-84ac-28d3c2b494e7.jpg" alt="Vector Search 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out" data-background='img/a1b5d3d8-9e8e-4a97-983c-82765f2833cc.png'>

<a id="f0dc280f-1db5-4258-ad5f-f04a1f40b2b9">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out" data-background='img/956f7e7e-d1aa-49a5-a47b-4dec4936596c.png'>

<a id="1ea48dff-202e-4774-9d17-fc2c7e4201cb">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out" data-background='img/86fdd248-e651-4290-9f72-e1c1295669c1.png'>
<aside class="notes"><p>Was a24b75f3-4f6c-4715-be5f-740a597cd3b3</p>
</aside>
<a id="56467599-0c70-4e59-b4a7-472ced422c84">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out">
<a id="c0856058-b753-43da-bbf7-fd6bab107e7a"><h1>Resume Scanning</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:afa0ae28-cd12-4714-82c0-d9d6686f2230 -->
<!-- ContentItem:412011fa-11c7-4b62-8bac-9c3d8af4c3e7 -->
<aside class="notes"><p>Jonathon_Nixon_8: 0.148041
Armando_Castro_10: 0.165220
Armando_Castro_8: 0.166799</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>Armando's Resume: 12.7% &quot;worse&quot;
<ul>
<li>More distant from a match to the job listing</li>
<li>A 95 for Jonathon's resume â‰ˆ an 84 for Armando's</li>
</ul>
</li>
<li>If Armando had 2 additional years of experience
<ul>
<li>His score only increases by â‰ˆ 1 point to 85</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/412011fa-11c7-4b62-8bac-9c3d8af4c3e7.jpg" alt="TwoResumes_800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<aside class="notes"><p>Searches based on the Cosine Similarity of Embeddings don't leverage the attention mechanisms of the model. They only measure the aggregate distance of the tokens from the other items in the search.</p>
</aside>
<a id="7b5a883a-dea6-49e7-9edb-786b6298ed62"><h1>Embeddings Search</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:54ddbe15-27b7-4e55-813f-db3a52ec54e1 -->
<img alt="Transformer Architectures - Embedding Only - 938x800.png" src="img/54ddbe15-27b7-4e55-813f-db3a52ec54e1.png" />
</section>


<section data-transition="slide-in slide-out">
<a id="ac3355bd-37f8-4362-a7ce-1e75bfdbaaf1"><h1>Cosine Distances</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:bdd399e9-f225-4943-bf1a-26b57c78fbee -->
<!-- ContentItem:88b85f91-aa78-4683-bec1-20b4655d7cf3 -->
<aside class="notes"><p>We never told the model what was important to us, and we never even allowed the Attention mechanism to try to figure it out. Instead, it just looked at the differences between the tokens, and found Argentina to be farther from the US than the UK is.</p>
</aside>
<table><tr><td style="vertical-align:top;">
<table>
<thead>
<tr>
<th>Country</th>
<th>D(USA,C)</th>
</tr>
</thead>
<tbody>
<tr>
<td>United Kingdom</td>
<td>0.11981422</td>
</tr>
<tr>
<td>United Kingdom of Great Britain and Northern Ireland</td>
<td>0.16426033</td>
</tr>
<tr>
<td>England</td>
<td>0.16678649</td>
</tr>
<tr>
<td>Argentine Republic</td>
<td>0.18766826</td>
</tr>
<tr>
<td>RepÃºblica Argentina</td>
<td>0.20281911</td>
</tr>
</tbody>
</table>

</td>
<td style="text-align: left;">
<img src="img/88b85f91-aa78-4683-bec1-20b4655d7cf3.png" alt="Country Distances.png" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="4ead4f8a-8956-4f5b-8ada-a16a7e883b8f"><h1>Embeddings Differences</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:cfd42d94-fa37-4878-b2ac-acfb2f3c1bbe -->
<!-- ContentItem:d9562b82-479e-47cc-9074-3abaae05babd -->
<aside class="notes"><p>There are lots of reasons why the embeddings relating the US &amp; Argentina are farther apart than US vs UK. They all have to do with how the Embeddings are encoded.</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>Language
<ul>
<li>English (different dialects) vs Spanish</li>
</ul>
</li>
<li>Historical Ties
<ul>
<li>USA and UK - Political (colonial), economic and cultural ties</li>
</ul>
</li>
<li>Cultural Similarities
<ul>
<li>USA and UK - shared media, literature, entertainment, and educational exchanges including TV, movies, music, and news</li>
</ul>
</li>
<li>Political Systems
<ul>
<li>USA and UK - Democracies w/ common roots</li>
</ul>
</li>
<li>Other differences
<ul>
<li>Economic Ties</li>
<li>Geopolitical Alliances</li>
<li>Educational Systems</li>
<li>Legal Systems</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/d9562b82-479e-47cc-9074-3abaae05babd.jpg" alt="Embedding Differences - USA UK Argentina - 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out" data-background='img/01f8802f-7db6-4312-9064-54ec9739692a.png'>
<aside class="notes"><p>I think we got lucky that adding 2 years made Armando's resume better. It could just as easily gotten worse.</p>
</aside>
<a id="cba9750d-b194-4ea8-a8a2-ebeeca872161">&nbsp;</a>
<!-- Layout:FullPage -->

</section>


<section data-transition="slide-in slide-out">
<a id="0d9091f3-e87c-42ca-aff2-ad4f91ea332b"><h1>Resume Clustering</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:36ba17df-344e-4f5a-83a9-7c524b8e39ab -->
<!-- ContentItem:53a6cce5-95de-4e12-8035-bf68503c1bbe -->
<aside class="notes"><p>Clusters contains items more similar to each other than to those in other clusters</p>
<p>Things get even better if we can bring the attention mechanisms into play. i.e. we leverage embeddings of the GPT summary of the resume, excluding the name and location</p>
<p>Source Image: <a href="https://www.bing.com/images/search?view=detailV2&amp;ccid=vNng%2foOs&amp;id=2652F88E274436CB6C8CC623A778D7B9F2475FC9&amp;thid=OIP.vNng_oOsNRHKrlh3pjSAyAHaDw&amp;mediaurl=https%3a%2f%2fi.stack.imgur.com%2fcIDB3.png&amp;cdnurl=https%3a%2f%2fth.bing.com%2fth%2fid%2fR.bcd9e0fe83ac3511caae5877a63480c8%3frik%3dyV9H8rnXeKcjxg%26pid%3dImgRaw%26r%3d0&amp;exph=517&amp;expw=1017&amp;q=k-means+clustering&amp;simid=608026322933788461&amp;FORM=IRPRST&amp;ck=8E4BDA3E627011B4CADA2B68FB818490&amp;selectedIndex=0&amp;qft=+filterui%3alicenseType-Any&amp;ajaxhist=0&amp;ajaxserp=0">https://www.bing.com/images/search?view=detailV2&amp;ccid=vNng%2foOs&amp;id=2652F88E274436CB6C8CC623A778D7B9F2475FC9&amp;thid=OIP.vNng_oOsNRHKrlh3pjSAyAHaDw&amp;mediaurl=https%3a%2f%2fi.stack.imgur.com%2fcIDB3.png&amp;cdnurl=https%3a%2f%2fth.bing.com%2fth%2fid%2fR.bcd9e0fe83ac3511caae5877a63480c8%3frik%3dyV9H8rnXeKcjxg%26pid%3dImgRaw%26r%3d0&amp;exph=517&amp;expw=1017&amp;q=k-means+clustering&amp;simid=608026322933788461&amp;FORM=IRPRST&amp;ck=8E4BDA3E627011B4CADA2B68FB818490&amp;selectedIndex=0&amp;qft=+filterui%3alicenseType-Any&amp;ajaxhist=0&amp;ajaxserp=0</a></p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>Clustering
<ul>
<li>Unsupervised machine learning technique</li>
<li>Clusters form around centroids (the geometric center)</li>
<li>Data points are grouped (clustered) based on similarity</li>
<li>Minimize the error (distance from centroid)</li>
</ul>
</li>
<li>Resume Clustering
<ul>
<li>Identify a group of relevant resumes</li>
<li>Not for <em>ranking</em>, just <em>filtering</em></li>
<li>Cluster the resumes, the GPT summaries, or both</li>
<li>Still not perfect</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/53a6cce5-95de-4e12-8035-bf68503c1bbe.png" alt="k-means results.png" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<aside class="notes"><p>One big risk here is that one or more aspects of the summary may be wrong,  and those could be the result of systemic bias.
Remember: &quot;CAN&quot; does not mean &quot;SHOULD&quot;.</p>
</aside>
<a id="66b92892-456e-41cd-b779-105e77d1190b"><h1>Resume Summarization</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:e0550c18-b794-49f1-9b89-89aacdc847d9 -->
<ul>
<li><p><em>System</em>: As a resume scanner specializing in software engineers, focus solely on summarizing their key skills and experience durations, omitting demographics like age and location.</p>
</li>
<li><p><em>User</em>: [Submits appropriate resume]</p>
</li>
<li><p><em>Assistant</em>:</p>
</li>
</ul>
<pre><code class="language-**Key">- Expertise in Java, J2EE, Spring Framework, Hibernate
- Experience with front-end technologies such as HTML, CSS, JavaScript, and AngularJS
- Proficient in SQL databases and ORM technologies
- Familiar with containerization and orchestration tools like Docker and Kubernetes
- Strong understanding of software design patterns and best practices
- Excellent problem-solving abilities and attention to detail
- Effective team player with strong communication skills

**Experience:**
- Senior Java Developer at XYZ Tech Solutions (June 2016 â€“ Present, 5 years)
- Java Software Engineer at Innovative Software Co. (May 2012 â€“ May 2016, 4 years)

**Certifications:**
- Oracle Certified Professional, Java SE 8 Programmer
- Certified ScrumMaster (CSM)

**Education:**
- Bachelor of Science in Computer Science, University of Technical Excellence (Graduated: May 2012)
</code></pre>

</section>


<section data-transition="slide-in slide-out">
<a id="f8c3912e-08e3-46e9-b5b9-92f492e5780b"><h1>Retrieval Augmented Generation (RAG)</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:7d502157-fe4b-4891-9ddb-90d231368958 -->
<!-- ContentItem:77d9dede-033f-4a7a-9f4f-e56b4632a73e -->
<aside class="notes"><p>If we are not augmenting the model with our own data, we are just hoping the model  happens to be trained on the right things for our use-case.</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>Combines the benefits of retrieval-based and generative models
<ul>
<li>Identify and retrieve relevant information</li>
<li>Agument context of the generative models</li>
<li>Generative responses based on the augmented context</li>
</ul>
</li>
<li>Potential uses include
<ul>
<li>Explore large sets of documentation conversationally</li>
<li>Generate recommendations and insights based on retrieved relevant information</li>
<li>Summarization of articles in light of known relevant information</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/77d9dede-033f-4a7a-9f4f-e56b4632a73e.jpg" alt="RAG 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">

<a id="f1a2a6fe-439d-435e-b9e8-20af0aa13d69"><h1>Beary - The Beary Barry Bot</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:0538ef66-2942-4c64-8b4e-7f5fb652be13 -->
<img alt="Beary_600x600.png" src="img/0538ef66-2942-4c64-8b4e-7f5fb652be13.png" />
</section>


<section data-transition="slide-in slide-out">

<a id="6ed666b8-ccc0-4ce0-b035-1e5532a9ea77"><h1>Beary Flow</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:dd5439d2-6794-4c28-adff-2964a833995b -->
<img alt="Beary Demo - Flowchart - Horizontal Flow - 1280x381.png" src="img/dd5439d2-6794-4c28-adff-2964a833995b.png" />
</section>


<section data-transition="slide-in slide-out">
<a id="a90739ca-6f34-43a1-9ed7-08c8a91a1f2f"><h1>No More Search Engines</h1></a>
<!-- Layout:ImageWithCaption -->
<!-- ContentItem:58f71386-37a3-4e9e-8c8b-f3f1cf9cda23 -->
<!-- ContentItem:6ed8ae72-9bf0-46b5-98f6-912d25c0bf74 -->
<aside class="notes"><p>We are using probabilistic models to generate recommendations  about what information our users need to know. This means we need to start thinking differently about how we gather data to  present to the user.</p>
</aside>
<img alt="Information Recommendation 600x600.jpeg" src="img/58f71386-37a3-4e9e-8c8b-f3f1cf9cda23.jpeg" />
<h2><h3 id="we-now-use-information-recommendation-engines">We now use Information Recommendation Engines</h3>
</h2>
</section>

<section data-transition="slide-in slide-out">
<a id="923a9b20-f827-4a7f-947e-ee501fff9a15"><h1>More than just a query</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:0bfd3d5b-dabe-4511-895f-8bd44df89c89 -->
<!-- ContentItem:8c3f9082-b1c9-4c8b-a49e-765712b374d7 -->

<table><tr><td style="vertical-align:top;">
<blockquote>
<p>Don't leave important information &quot;on the table&quot;</p>
</blockquote>
<ul>
<li>Leverage contextual data to enrich the user experience
<ul>
<li>Ensure interactions are relevant</li>
</ul>
</li>
<li>Always Maintain high standards
<ul>
<li>User Privacy</li>
<li>User Data Protection</li>
<li>Consent where appropriate</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/8c3f9082-b1c9-4c8b-a49e-765712b374d7.jpeg" alt="More than Just a Query 800x800.jpeg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="658580b3-48e9-4904-a8bd-de4d83fd2aa2"><h1>Contextual Clues</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:29a14869-a948-49c5-9a0e-c31b54ad4aa8 -->
<!-- ContentItem:15661a21-92bf-4901-976a-258f795ce935 -->
<aside class="notes"><p>We should not be <strong>collecting</strong> this data, but instead leveraging it  in real-time to provide a better user experience</p>
</aside>
<table><tr><td style="vertical-align:top;">
<blockquote>
<p>Use Responsibly - Be careful to respect user privacy</p>
</blockquote>
<ul>
<li>Time of Day &amp; Week: Routine vs urgent</li>
<li>Mouse &amp; Eye Movements: Regions of interest</li>
<li>Device &amp; Platform: Accessibility preferences</li>
<li>Location: Geographical relevance</li>
<li>Browsing History: Interests</li>
<li>Social Media: Personal interests</li>
<li>Purchases: Preferences and future needs</li>
<li>Content Consumption Rate: Casual vs focused</li>
<li>Feedback: Satisfaction and preferences</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/15661a21-92bf-4901-976a-258f795ce935.jpeg" alt="Contextual Clues 800x800.jpeg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="95a50a2a-56dc-42b9-b6d2-cb9029614d84"><h1>Yo Dawg!</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:85b4667c-9231-4915-a037-fdf51688cc08 -->
<!-- ContentItem:f1a37766-6a5c-4088-af98-99ce2d7a7d22 -->
<aside class="notes"><p>Image Created by Dall-e via Microsoft Designer, 2024-09-22</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>I heard you like 'cooking'  so I calculated some recipes from your shopping list so you so you can turn that grocery haul into a Michelin-star meal</li>
<li>I heard you like 'photography',  so I enhanced your photos with your most-used AI filters  so your style shines through</li>
<li>I heard you like 'apple products' so I ordered you a ladder so you can reach those <em>elevated features</em></li>
<li>I heard you like coffee,  so I scoured local social-media to make you a map  so you can find all the best hidden cafes in town</li>
<li>I heard you like 'JavaScript'  so I created a playlist for you composed entirely of loops so you can get into the proper frame-of-mind for coding</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/f1a37766-6a5c-4088-af98-99ce2d7a7d22.jpg" alt="Definitely not Xzibit 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<aside class="notes"><p>The ethics of AI are complex, and you should explore them. The simplest rule is: &quot;If you can't build it ethically with an AI model, don't build it with an AI model&quot;</p>
<p>Image Source: <a href="https://www.bing.com/images/search?view=detailV2&amp;ccid=SF5NW%2F2E&amp;id=867710BF172B3480BE22F1F1FE19397AE0A6FE8A&amp;thid=OIP.SF5NW_2E8OBt2DbDD1pomgHaDE&amp;mediaurl=https%3A%2F%2Fth.bing.com%2Fth%2Fid%2FR.485e4d5bfd84f0e06dd836c30f5a689a%3Frik%3Div6m4Ho5Gf7x8Q%26riu%3Dhttp%253a%252f%252fmarcogomes.com%252fblog%252fwp-content%252fuploads%252f2010%252f09%252fherebedragons.jpg%26ehk%3DFB%252fMQocKYDXUvxHKhrvHWg9Meu0PUBJWlSnfk%252bjgSp4%253d%26risl%3D%26pid%3DImgRaw%26r%3D0%26sres%3D1%26sresct%3D1&amp;exph=224&amp;expw=540&amp;q=here+there+be+dragons&amp;simid=608053647533357231&amp;form=IRPRST&amp;ck=2AD9AF425E791ED0BDF2696C5EB0557E&amp;selectedindex=7&amp;qft=+filterui%3alicenseType-Any&amp;ajaxhist=0&amp;ajaxserp=0&amp;vt=2&amp;sim=15,16&amp;ajaxhist=0&amp;ajaxserp=0">https://www.bing.com/images/search?view=detailV2&amp;ccid=SF5NW%2F2E&amp;id=867710BF172B3480BE22F1F1FE19397AE0A6FE8A&amp;thid=OIP.SF5NW_2E8OBt2DbDD1pomgHaDE&amp;mediaurl=https%3A%2F%2Fth.bing.com%2Fth%2Fid%2FR.485e4d5bfd84f0e06dd836c30f5a689a%3Frik%3Div6m4Ho5Gf7x8Q%26riu%3Dhttp%253a%252f%252fmarcogomes.com%252fblog%252fwp-content%252fuploads%252f2010%252f09%252fherebedragons.jpg%26ehk%3DFB%252fMQocKYDXUvxHKhrvHWg9Meu0PUBJWlSnfk%252bjgSp4%253d%26risl%3D%26pid%3DImgRaw%26r%3D0%26sres%3D1%26sresct%3D1&amp;exph=224&amp;expw=540&amp;q=here+there+be+dragons&amp;simid=608053647533357231&amp;form=IRPRST&amp;ck=2AD9AF425E791ED0BDF2696C5EB0557E&amp;selectedindex=7&amp;qft=+filterui%3alicenseType-Any&amp;ajaxhist=0&amp;ajaxserp=0&amp;vt=2&amp;sim=15,16&amp;ajaxhist=0&amp;ajaxserp=0</a></p>
</aside>
<a id="c28997ab-1cec-407e-b069-06efd5dc5a7f"><h1>Using LLM Output Has Dangers</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:d950c2c7-f2fe-4af9-b210-18d33c40661a -->
<img alt="herebedragons.jpg" src="img/d950c2c7-f2fe-4af9-b210-18d33c40661a.jpg" />
</section>


<section data-transition="slide-in slide-out">
<a id="302ab20a-f006-4521-8c30-2dbc46d99ed6"><h1>Model Answers May Be</h1></a>
<!-- Layout:MultiColumn -->
<!-- ContentItem:540f4702-43af-4a34-915e-6f8ec49ca672 -->
<!-- ContentItem:3b97dc48-fe4a-4f30-8139-3aa93949bd6b -->
<aside class="notes"><p>Whether using GPT directly or semantic search with embeddings.
Old image: 59bf56c7-2e3d-4a25-b78e-ade863990440</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>Incomplete</li>
<li>Poorly phrased</li>
<li>Outright wrong</li>
</ul>

</td>
<td style="vertical-align:top;">
<img alt="No Takesies backsies.png" src="img/3b97dc48-fe4a-4f30-8139-3aa93949bd6b.png" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="08f50362-8bf7-48a2-a61a-0980f21d9a19"><h1>The model is biased</h1></a>
<!-- Layout:MultiColumn -->
<!-- ContentItem:0b06fef2-cc47-4acb-963e-4aa8a1a2aaeb -->
<!-- ContentItem:0c946a74-2029-4651-9eee-a2645dba9317 -->

<table><tr><td style="vertical-align:top;">
<ul>
<li>Not handling the bias makes bias a feature of your app
<ul>
<li>Understand what fairness means in your context</li>
<li>Understand the impact of being wrong</li>
</ul>
</li>
<li>Take fairness very seriously
<ul>
<li>Prevent all predictable biases</li>
<li>Monitor for unpredictable biases</li>
</ul>
</li>
</ul>

</td>
<td style="vertical-align:top;">
<img alt="bias logo - large.jpg" src="img/0c946a74-2029-4651-9eee-a2645dba9317.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="c77448f6-5c86-44aa-96a4-e5d960c222ef"><h1>Embeddings are Reversable</h1></a>
<!-- Layout:MultiColumn -->
<!-- ContentItem:cccf95ad-420d-4027-ba9d-8e33f762eb6b -->
<!-- ContentItem:18980ad3-d112-4fd7-9221-717689b8ae12 -->
<aside class="notes"><p>Article from Linus Lee of Notion linked on Resources slide</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>Researchers have had success in reversing embeddings
<ul>
<li>Using distance-measurements against a large Vector DB</li>
<li>Using models trained to predict the text from the embedding</li>
</ul>
</li>
<li>Embeddings can be thought-of like a hash
<ul>
<li>Data is obscured, but not encrypted</li>
</ul>
</li>
<li>Do not expect embeddings alone to protect PII
<ul>
<li>Encrypt or tokenize all PII before embedding</li>
</ul>
</li>
</ul>

</td>
<td style="vertical-align:top;">
<img alt="Simpleicons_Interface_unlocked-padlock - Red 600x600.png" src="img/18980ad3-d112-4fd7-9221-717689b8ae12.png" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">
<a id="944ae71d-a8b3-4de4-9a9e-ffeef6e07fcd"><h1>When Should AI be Used?</h1></a>
<!-- Layout:ImageRight -->
<!-- ContentItem:0b8f654e-2dc5-41c1-b195-f0495b79d62e -->
<!-- ContentItem:2f5756ee-7bb2-49ea-9982-bc08c8ce72f9 -->
<aside class="notes"><p>I worry that situations where it is safe to use these models are more rare than people realize or are willing to accept. That said, we can't let the only people building using AI models be those whose only goal is to separate us from our wealth.</p>
</aside>
<table><tr><td style="vertical-align:top;">
<ul>
<li>When all possible biases have been accounted for</li>
<li>When all sensitive data has been removed, tokenized or encrypted</li>
<li>When the stochastic nature of responses has been accounted for
<ul>
<li>A wrong answer is no worse than no answer</li>
<li>Outputs have been fully constrained</li>
<li>A human is in-the-loop to fix the inevitable errors</li>
</ul>
</li>
</ul>

</td>
<td style="text-align: left;">
<img src="img/2f5756ee-7bb2-49ea-9982-bc08c8ce72f9.jpg" alt="When to use AI 800x800.jpg" />
</td>
</tr></table></section>

<section data-transition="slide-in slide-out">

<a id="ac8bc960-baa4-41e1-a289-3d2352f7cf96"><h1>What Are Embeddings?</h1></a>
<!-- Layout:FullPage -->
<!-- ContentItem:41ce545a-ffe3-4ec6-b4c6-43c4516c63b1 -->
<ul>
<li>Arrays of 1536 floating-point values</li>
<li>Structured numeric data that represents unstructured text</li>
<li>Representations of the semantics and context of the source text</li>
<li>Vectors that support standard mathematical operations</li>
</ul>

</section>


<section data-transition="slide-in slide-out">
<a id="8c8e5769-8a07-4a92-a315-1a02d79c9bfb"><h1>Resources</h1></a>
<!-- Layout:MultiColumn -->
<!-- ContentItem:97720f70-277d-44b0-b113-274ffa0db619 -->

<table><tr><td style="vertical-align:top;">
<ul>
<li>This Presentation - <a href="https://RAGDeepDive.azurewebsites.net/">Web</a> | <a href="?print-pdf">PDF</a></li>
<li>These Demos - <a href="https://github.com/bsstahl/AIDemos/tree/master/Embeddings">Code</a> | <a href="https://github.com/bsstahl/AIDemos/wiki/Embeddings">Docs</a></li>
<li><a href="https://cognitiveinheritance.com/Posts/depth-of-gpt-embeddings.html">The Depth of GPT Embeddings</a></li>
<li><a href="https://cognitiveinheritance.com/Posts/Programmers-Take-Responsibility-for-Your-AIe28099s-Output.html">Programmers -- Take Responsibility for Your AIâ€™s Output</a></li>
<li><a href="https://thesephist.notion.site/text-embedding-ada-002-embedding-reconstructions-2ea55ae9525d49dfa9d16213474e0895">Experiments in Reconstructing Text from Embeddings</a></li>
<li><a href="https://github.com/Azure/azure-sdk-for-net/tree/main/sdk/openai/Azure.AI.OpenAI">Azure OpenAI Client</a></li>
<li><a href="https://github.com/microsoft/semantic-kernel">Semantic Kernel</a></li>
<li><a href="https://www.youtube.com/watch?v=UnURElCzGc0">Carl Sagan - Reasoning on Higher Dimensions (YouTube)</a></li>
</ul>

</td>
</tr></table></section>


        </div>
        <div class="footer-left">The Future of Information Retrieval</div>
        <div class="footer-right">Barry S. Stahl - Mastodon:@bsstahl@cognitiveinheritance.com - Blog:http://www.cognitiveinheritance.com</div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>
        // More info about config & dependencies:
        // - https://github.com/hakimel/reveal.js#configuration
        // - https://github.com/hakimel/reveal.js#dependencies


        Reveal.initialize({
			width: 1920,
			height: 1080,
            transition: 'slide',
            showNotes: window.location.search.match(/print-pdf/gi) ? true : false,
            dependencies: [
                { src: 'plugin/markdown/marked.js' },
                { src: 'plugin/markdown/markdown.js' },
                { src: 'plugin/notes/notes.js', async: true },
				{ src: 'plugin/zoom-js/zoom.js', async: true },
                { src: 'plugin/highlight/highlight.js', async: true, callback: function () { hljs.initHighlightingOnLoad(); } }
            ]
        });
    </script>
</body>
</html>
