<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cognitive Inheritance</title>
    <description>The Application Development Experiences of an Enterprise Developer</description>
    <link>http://www.cognitiveinheritance.com/</link>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>Prehensile Pony Tail 1.0</generator>
    <language>en-US</language>
    <atom:link href="https://cognitiveinheritance.com/syndication.xml" rel="self" type="application/rss+xml" />	
    <item>
  <title>The Critical C's of Microservices - Coalescence</title>
  <description>&lt;p&gt;&amp;quot;&lt;strong&gt;The Critical C&apos;s of Microservices&lt;/strong&gt;&amp;quot; are a series of conversations that development teams should have around building event-driven or other microservice based architectures. These topics will help teams determine which architectural patterns are best for them, and assist in building their systems and processes in a reliable and supportable way.&lt;/p&gt;
&lt;p&gt;The &amp;quot;Critical C&apos;s&amp;quot; are: &lt;strong&gt;Context&lt;/strong&gt;, &lt;strong&gt;Consistency&lt;/strong&gt;, &lt;strong&gt;Contract&lt;/strong&gt;, &lt;strong&gt;Chaos&lt;/strong&gt;, &lt;strong&gt;Competencies&lt;/strong&gt; and &lt;strong&gt;Coalescence&lt;/strong&gt;. Each of these topics has been covered in detail in this series of 6 articles. The first article of the 6 was on the subject of &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-1of6-context.html&quot;&gt;Context&lt;/a&gt;. This is the final article in the series, and covers the topic of &lt;strong&gt;Coalescence&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;Coalescence&lt;/h4&gt;
&lt;p&gt;The use of Microservices reduces the complexity of our services in many ways, however it also adds complexity when it comes to deployment and operations. More services mean more deployments, even as each of those deployments is smaller and more isolated. Additionally, they can be harder on operations and support teams since there can be many more places to go when you need to find information. Ideally, we would coalesce all of the necessary information to operate and troubleshoot our systems in a single pane-of-glass so that our operations and support engineers don&apos;t have to search for information in a crisis.&lt;/p&gt;
&lt;p&gt;Deployment and system verification testing can help us identify when there are problems at any point in our system and give us insight into what the problems might be and what caused them. Tests run immediately after any deployment can help identify when a particular deployment has caused a problem so it can be addressed quickly. Likewise, ongoing system verification tests can give early indications of problems irrespective of the cause. Getting information about the results of these tests quickly and easily into the hands of the engineers that can act on them can reduce costs and prevent outages.&lt;/p&gt;
&lt;p&gt;Logging and traceability is generally considered a solved problem, so long as it is used effectively. We need to setup our systems to make the best use of our distributed logging systems. This often means adding a correlation identifier alongside various request and causation ids to make it easy to trace requests through the system. We also need to be able to monitor and surface our logs so that unusual activity can be recognized and acted on as quickly as possible.&lt;/p&gt;
&lt;p&gt;Service Level Indicators (SLIs) and other metrics can provide key insights into the operations of our systems, even if no unusual activity is seen within our logs. Knowing what operational metrics suggest there might be problems within our systems, and monitoring changes to those metrics for both our services and our dependencies can help identify, troubleshoot and even prevent outages. Surfacing those metrics for easy access can give our support and operations engineers the tools they need to do their jobs effectively.&lt;/p&gt;
&lt;h4&gt;Goals of the Conversation&lt;/h4&gt;
&lt;p&gt;Development teams should have conversations around &lt;strong&gt;Coalescence&lt;/strong&gt; that are primarily focused around brining critical information about the operation of our systems together for easy acess. These conversations should include answering questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is our mechanism for deployment and system verification?
&lt;ul&gt;
&lt;li&gt;How will we identify, as quickly as possible, when a deployment has had a negative impact on our system?&lt;/li&gt;
&lt;li&gt;Are there tests that can validate the operation of the system end-to-end?&lt;/li&gt;
&lt;li&gt;How will we surface the status of any deployment and system verification tests?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;What is our mechanism for logging/traceability within our system?
&lt;ul&gt;
&lt;li&gt;How will we coalesce our logs from the various services within the system?&lt;/li&gt;
&lt;li&gt;How will we know if there are anomalies in our logs?&lt;/li&gt;
&lt;li&gt;Are there additional identifiers we need to add to allow traceability?&lt;/li&gt;
&lt;li&gt;Are there log queries that, if enabled, might provide additional support during an outage?&lt;/li&gt;
&lt;li&gt;Are there ways to increase the level of logging when needed to provide additional information and can this be done wholistically on the system?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How will we expose SLIs and other metrics so they are available when needed?&lt;/li&gt;
&lt;li&gt;How will we know when there are anomalies in our metrics?&lt;/li&gt;
&lt;li&gt;What are the metrics that would be needed in an outage and how will we surface those for easy access?&lt;/li&gt;
&lt;li&gt;Are there additional metrics that, if enabled, might provide additional support during an outage?&lt;/li&gt;
&lt;li&gt;Are there ways to perform ad-hoc queries against SLIs and metrics to provide additional insight in an outage?&lt;/li&gt;
&lt;li&gt;How will we identify the status of dependencies so we can understand when our systems are reacting to downstream anomalies?
&lt;ul&gt;
&lt;li&gt;How will we surface dependency status for easy access during an outage?&lt;/li&gt;
&lt;li&gt;Are there metrics we can surface for our dependencies that might help during an outage?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-6of6-coalescence.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/a0280db3-6d32-4c89-81c4-10ce2cd3522d.html</guid>
  <pubDate>Mon, 16 Jan 2023 07:00:00 GMT</pubDate>
</item><item>
  <title>The Critical C's of Microservices - Competencies</title>
  <description>&lt;p&gt;&amp;quot;&lt;strong&gt;The Critical C&apos;s of Microservices&lt;/strong&gt;&amp;quot; are a series of conversations that development teams should have around building event-driven or other microservice based architectures. These topics will help teams determine which architectural patterns are best for them, and assist in building their systems and processes in a reliable and supportable way.&lt;/p&gt;
&lt;p&gt;The &amp;quot;Critical C&apos;s&amp;quot; are: &lt;strong&gt;Context&lt;/strong&gt;, &lt;strong&gt;Consistency&lt;/strong&gt;, &lt;strong&gt;Contract&lt;/strong&gt;, &lt;strong&gt;Chaos&lt;/strong&gt;, &lt;strong&gt;Competencies&lt;/strong&gt; and &lt;strong&gt;Coalescence&lt;/strong&gt;. Each of these topics will be covered in detail in this series of articles. The first article of the 6 was on the subject of &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-1of6-context.html&quot;&gt;Context&lt;/a&gt;. This is article 5 of the series, and covers the topic of &lt;strong&gt;Competencies&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;Competencies&lt;/h4&gt;
&lt;p&gt;It is our responsibility as engineers to spend our limited resources on those things that give the companies we are building for a competitive advantage in the market. This means limiting our software builds to areas where we can differentiate that company from others. Not every situation requires us to build a custom solution, and even when we do, there is usually no need for us to build every component of that system.&lt;/p&gt;
&lt;p&gt;If the problem we are solving is a common one that many companies deal with, and our solution does not give us a competitive advantage over those other companies, we are probably better off using an off-the-shelf product, whether that is a commercial (COTS) product, or a Free or Open-Source one (FOSS). Software we build should be unique to the company it is being built for, and provide that company with a competitive advantage. There is no need for us to build another Customer Relationship Manager (CRM) or Accounting system since these systems implement solutions to solved problemns that are generally solved in the same way by everyone. We should only build custom solutions if we are doing something that has never been done before or we need to do things in a way that is different from everyone else and can&apos;t be done using off-the-shelf systems.&lt;/p&gt;
&lt;p&gt;We should also only be building custom software when the problem being solved is part of our company&apos;s &lt;a href=&quot;https://en.wikipedia.org/wiki/Core_competency&quot; title=&quot;A combination of multiple resources and skills that distinguish a firm in the marketplace and therefore are the foundation of companies&apos; competitiveness&quot;&gt;core competencies&lt;/a&gt;. If we are doing this work for a company that builds widgets, it is unlikely, though not impossible, that building a custom solution for getting parts needed to build the widgets will provide that company with a competitive advantage. We are probably better off if we focus our efforts on software to help make the widgets in ways that are better, faster or cheaper.&lt;/p&gt;
&lt;p&gt;If our &amp;quot;build vs. buy&amp;quot; decision is to build a custom solution, there are likely to be opportunities within those systems to use pre-existing capabilities rather than writing everything from scratch. For example, many cross-cutting concerns within our applications have libraries that support them very effectively. We should not be coding our own implementations for things like &lt;a href=&quot;https://en.wikipedia.org/wiki/Logging_(computing)&quot; title=&quot;The act of keeping a log of events that occur in a computer system, such as problems, errors or just information on current operation&quot;&gt;logging&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Computer_configuration&quot; title=&quot;The arrangement of a system&apos;s functional units according to their nature, number and chief characteristics&quot;&gt;configuration&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Security&quot; title=&quot;Protection from or resilience against, potential harm (or other unwanted coercive change) caused by others, by restraining the freedom of others to act&quot;&gt;security&lt;/a&gt;. Likewise, there are many capabilities that already exist in our infrastructure that we should take advantage of. &lt;a href=&quot;https://en.wikipedia.org/wiki/Encryption&quot; title=&quot;The process of encoding information&quot;&gt;Encryption&lt;/a&gt;, which is often a capability of the operating system, is one that springs to mind. We should certainly never &amp;quot;roll-our-own&amp;quot; for more complex infrastructure features like &lt;a href=&quot;https://en.wikipedia.org/wiki/Replication_(computing)&quot; title=&quot;Sharing information so as to ensure consistency between redundant resources, such as software or hardware components, to improve reliability, fault-tolerance, or accessibility.&quot;&gt;Replication&lt;/a&gt; or &lt;a href=&quot;https://en.wikipedia.org/wiki/Change_data_capture&quot; title=&quot;CDC is a set of software design patterns used to determine and track the data that has changed so that action can be taken using the changed data.&quot;&gt;Change Data Capture&lt;/a&gt;, but might even want to consider avoiding rebuilding infrastructure capabilities that we more commonly build. An example of this might be if we would typically build a &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_API&quot; title=&quot;An Application Programming Interface exposed over HTTP(S)&quot;&gt;Web API&lt;/a&gt; for our systems, we might consider exposing the API&apos;s of our backing infrastructure components instead, properly isolated and secured of course, perhaps via an &lt;a href=&quot;https://en.wikipedia.org/wiki/API_management&quot; title=&quot;The process of creating and publishing web application programming interfaces (APIs), enforcing their usage policies, controlling access, nurturing the subscriber community, collecting and analyzing usage statistics, and reporting on performance&quot;&gt;API Management&lt;/a&gt; component.&lt;/p&gt;
&lt;h4&gt;Goals of the Conversation&lt;/h4&gt;
&lt;p&gt;Development teams should have conversations around &lt;strong&gt;Competencies&lt;/strong&gt; that are primarily focused around what systems, sub-systems, and components should be built, which should be installed off-the-shelf, and what libraries or infrastructure capabilities should be utilized. These conversations should include answering questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What are our core competencies?&lt;/li&gt;
&lt;li&gt;How do we identify &amp;quot;build vs. buy&amp;quot; opportunities?&lt;/li&gt;
&lt;li&gt;How do we make &amp;quot;build vs. buy&amp;quot; decisions on needed systems?&lt;/li&gt;
&lt;li&gt;How do we identify cross-cutting concerns and infrastructure capabilites that can be leveraged?&lt;/li&gt;
&lt;li&gt;How do we determine which libraries or infrastructure components will be utilized?&lt;/li&gt;
&lt;li&gt;How do we manage the versioning of utilized components, especially in regard to security updates?&lt;/li&gt;
&lt;li&gt;How do we document our decisions for later review?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Next Up - Coalescence&lt;/h4&gt;
&lt;p&gt;In the final article of this series we will look at &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-6of6-coalescence.html&quot;&gt;Coalescence&lt;/a&gt; and how we should work to bring all of the data together for our operations &amp;amp; support engineers.&lt;/p&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-5of6-competencies.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/a99861ed-9829-4110-9e2f-1e75efcb43a2.html</guid>
  <pubDate>Mon, 09 Jan 2023 07:00:00 GMT</pubDate>
</item><item>
  <title>The Critical C's of Microservices - Chaos</title>
  <description>&lt;p&gt;&amp;quot;&lt;strong&gt;The Critical C&apos;s of Microservices&lt;/strong&gt;&amp;quot; are a series of conversations that development teams should have around building event-driven or other microservice based architectures. These topics will help teams determine which architectural patterns are best for them, and assist in building their systems and processes in a reliable and supportable way.&lt;/p&gt;
&lt;p&gt;The &amp;quot;Critical C&apos;s&amp;quot; are: &lt;strong&gt;Context&lt;/strong&gt;, &lt;strong&gt;Consistency&lt;/strong&gt;, &lt;strong&gt;Contract&lt;/strong&gt;, &lt;strong&gt;Chaos&lt;/strong&gt;, &lt;strong&gt;Competencies&lt;/strong&gt; and &lt;strong&gt;Coalescence&lt;/strong&gt;. Each of these topics will be covered in detail in this series of articles. The first article of the 6 was on the subject of &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-1of6-context.html&quot;&gt;Context&lt;/a&gt;. This is article 4 of the series, and covers the topic of &lt;strong&gt;Chaos&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;Chaos&lt;/h4&gt;
&lt;p&gt;One of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing&quot;&gt;Fallacies of Distributed Computing&lt;/a&gt; is that the network is reliable. We should have similarly low expectations for the reliability of all of the infrastructure on which our services depend. Networks will segment, commodity servers and drives will fail, containers and operating systems will become unstable. In other words, our software will have errors during operation, no matter how resilient we attempt to make it. We need to embrace the fact that failures will occur in our software, and will do so at random times and often in unpredictable ways.&lt;/p&gt;
&lt;p&gt;If we are to build systems that don&apos;t require our constant attention, especially during off-hours, we need to be able to identify what happens when failures occur, and design our systems in ways that will allow them to heal automatically once the problem is corrected.&lt;/p&gt;
&lt;p&gt;To start this process, I recommend playing &amp;quot;what-if&amp;quot; games using diagrams of the system. Walk through the components of the system, and how the data flows through it, identifying each place where a failure could occur. Then, in each area where failures could happen, attempt to define the possible failure modes and explore what the impact of those failures might be. This kind of &amp;quot;virtual&amp;quot; Chaos Engineering is certainly no substitute for actual experimentation and testing, but is a good starting point for more in-depth analysis. It also can be very valuable in helping to understand the system and to produce more hardened services in the future.&lt;/p&gt;
&lt;p&gt;Thought experiments are useful, but you cannot really know how a system will respond to different types of failures until you have those failures in production. Historically, such &amp;quot;tests&amp;quot; have occurred at random, at the whim of the infrastructure, and usually at the worst possible time. Instead of leaving these things to chance, tools like &lt;em&gt;Chaos Monkey&lt;/em&gt; can be used to simulate failures in production, and can be configured to create these failures during times where the appropriate support engineers are available and ready to respond if necessary. This way, we can see if our systems respond as we expect, and more importantly, heal themselves as we expect.&lt;/p&gt;
&lt;p&gt;Even if you&apos;re not ready to jump into using automated experimentation tools in production just yet, a lot can be learned from using feature-flags and changing service behaviors in a more controlled manner as a starting point. This might involve a flag that can be set to cause an API method to return an error response, either as a hard failure, or during random requests for a period of time. Perhaps a switch could be set to stop a service from picking-up asynchronous messages from a queue or topic. Of course, these flags can only be placed in code we control, so we can&apos;t test failures of dependencies like databases and other infrastructure components in this way. For that, we&apos;ll need more involved testing methods.&lt;/p&gt;
&lt;p&gt;Regardless of how we test our systems, it is important that we do everything we can to build systems that will heal themselves without the need for us to intervene every time a failure occurs. As a result, I highly recommend using asynchronous messaging patterns whenever possible. The asynchrony of these tools allow our services to be &amp;quot;temporally decoupled&amp;quot; from their dependencies. As a result, if a container fails and is restarted by Kubernetes, any message in process is rolled-back onto the queue or topic, and the system can pick right up where it left off.&lt;/p&gt;
&lt;h4&gt;Goals of the Conversation&lt;/h4&gt;
&lt;p&gt;Development teams should have conversations around &lt;strong&gt;Chaos&lt;/strong&gt; that are primarily focused around procedures for identifying and remediating possible failure points in the application. These conversations should include answering questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How will we evaluate potential sources of failures in our systems before they are built?
&lt;ul&gt;
&lt;li&gt;How will we handle the inability to reach a dependency such as a database?&lt;/li&gt;
&lt;li&gt;How will we handle duplicate messages sent from our upstream data sources?&lt;/li&gt;
&lt;li&gt;How will we handle messages sent out-of-order from our upstream data sources?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How will we expose possible sources of failures during any pre-deployment testing?&lt;/li&gt;
&lt;li&gt;How will we expose possible sources of failures in the production environment before they occur for users?&lt;/li&gt;
&lt;li&gt;How will we identify errors that occur for users within production?&lt;/li&gt;
&lt;li&gt;How will we prioritize changes to the system based on the results of these experiments?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Next Up - Competencies&lt;/h4&gt;
&lt;p&gt;In the next article of this series we will look at &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-5of6-competencies.html&quot;&gt;Competencies&lt;/a&gt; and how we should focus at least as much on what we build as how we build it.&lt;/p&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-4of6-chaos.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/0d794105-ef08-4465-b806-4a8eff7523c7.html</guid>
  <pubDate>Mon, 02 Jan 2023 07:00:00 GMT</pubDate>
</item><item>
  <title>The Critical C's of Microservices - Contract</title>
  <description>&lt;p&gt;&amp;quot;&lt;strong&gt;The Critical C&apos;s of Microservices&lt;/strong&gt;&amp;quot; are a series of conversations that development teams should have around building event-driven or other microservice based architectures. These topics will help teams determine which architectural patterns are best for them, and assist in building their systems and processes in a reliable and supportable way.&lt;/p&gt;
&lt;p&gt;The &amp;quot;Critical C&apos;s&amp;quot; are: &lt;strong&gt;Context&lt;/strong&gt;, &lt;strong&gt;Consistency&lt;/strong&gt;, &lt;strong&gt;Contract&lt;/strong&gt;, &lt;strong&gt;Chaos&lt;/strong&gt;, &lt;strong&gt;Competencies&lt;/strong&gt; and &lt;strong&gt;Coalescence&lt;/strong&gt;. Each of these topics will be covered in detail in this series of articles. The first article of the 6 was on the subject of &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-1of6-context.html&quot;&gt;Context&lt;/a&gt;. This is article 3 of the series, and covers the topic of &lt;strong&gt;Contract&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;Contract&lt;/h4&gt;
&lt;p&gt;Once a message has been defined and agreed to as an integration mechanism, all stakeholders in that integration have legitimate expectations of that message contract. Primarily, these expectations includes the agreed-to level of compatibility of future messages, and what the process will be when the contract needs to change. These guarantees will often be such that messages can add fields as needed, but cannot remove, move, or change the nature of existing fields without significant coordination with the stakeholders. This can have a severe impact on the &lt;strong&gt;agility&lt;/strong&gt; of our dev teams as they try to move fast and iterate with their designs.&lt;/p&gt;
&lt;p&gt;In order to keep implementations flexible, there should be an isolation layer between the internal representation (Domain Model) of any message, and the more public representation (Integration Model). This way, the developers can change the internal representation with only limited restrictions, so long as as the message remains transformationally compatible with the integration message, and the transformation is modified as needed so that no change is seen by the integration consumers. The two representations may take different forms, such as one in a database, the other in a Kafka topic. The important thing is that the developers can iterate quickly on the internal representation when they need to.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cognitiveinheritance.com/Images/CTP%20Pattern%20-%20Eventually%20Consistent.png&quot; alt=&quot;Drawing showing 2 different representations of a WorkOrder in the same Workflow - 1 stored in the DB the other in Kafka&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Eventually Consistent&lt;/strong&gt; example from the earlier &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-2of6-consistency.html&quot;&gt;Consistency&lt;/a&gt; topic (included above) shows such an isolation layer since the &lt;em&gt;WorkOrders DB&lt;/em&gt; holds the internal representation of the message, the &lt;em&gt;Kafka Connect&lt;/em&gt; connector is the abstraction that performs the transformation as needed, and the topic that the connector produces data to is the integration path. In this model, the development team can iterate on the model inside the DB without necessarily needing to make changes to the more public Kafka topic.&lt;/p&gt;
&lt;p&gt;We need to take great care to defend these internal streams and keep them isolated. Ideally, only 1 service should ever write to our domain model, and only internal services, owned by the same small development team, should read from it. As soon as we allow other teams into our domain model, it becomes an integration model whether we want it to be or not. Even other internal services should use the public representation if it is reasonable to do so.&lt;/p&gt;
&lt;p&gt;Similarly, our services should make proper use of upstream integration models. We need to understand what level of compatibility we can expect and how we will be notified of changes. We should use these data paths as much as possible to bring external data locally to our services, in exactly the form that our service needs it in, so that each of our services can own its own data for both reliability and efficiency. Of course, these local stores must be read-only. We need to publish change requests back to the &lt;em&gt;System of Record&lt;/em&gt; to make any changes to data sourced by those systems.&lt;/p&gt;
&lt;p&gt;We should also do everything we can to avoid making assumptions about data we don&apos;t own. Assuming a data type, particular provenance, or embedded-intelligence of a particular upstream data field will often cause problems in the future because we have created unnecessary coupling. As an example, it is good practice to treat all foreign identifiers as strings, even if they look like integers, and to never make assumptions along the lines of &amp;quot;...those identifiers will always be increasing in value&amp;quot;. While these may be safe assumptions for a while, they should be avoided if they reasonably can be to prevent future problems.&lt;/p&gt;
&lt;h4&gt;Goals of the Conversation&lt;/h4&gt;
&lt;p&gt;Development teams should have conversations around &lt;strong&gt;Contract&lt;/strong&gt; that are primarily focused around creating processes that define any integration contracts for both upstream and downstream services, and serve to defend their internal data representations against any external consumers. These conversations should include answering questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How will we isolate our internal data representations from those of our downstream consumers?&lt;/li&gt;
&lt;li&gt;What types of compatibility guarantees are our tools and practices capable of providing?&lt;/li&gt;
&lt;li&gt;What procedures should we have in place to monitor incoming and outgoing contracts for compatibility?&lt;/li&gt;
&lt;li&gt;What should our procedures look like for making a change to a stream that has downstream consumers?&lt;/li&gt;
&lt;li&gt;How can we leverage upstream messaging contracts to further reduce the coupling of our systems to our upstream dependencies?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Next Up - Chaos&lt;/h4&gt;
&lt;p&gt;In the next article of this series we will look at &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-4of6-chaos.html&quot;&gt;Chaos&lt;/a&gt; and how we can use both thought and physical experiments to help improve our system&apos;s reliability.&lt;/p&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-3of6-contract.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/d4b58b20-d4d7-4234-a828-4563d68db564.html</guid>
  <pubDate>Mon, 26 Dec 2022 07:00:00 GMT</pubDate>
</item><item>
  <title>The Critical C's of Microservices - Consistency</title>
  <description>&lt;p&gt;&amp;quot;&lt;strong&gt;The Critical C&apos;s of Microservices&lt;/strong&gt;&amp;quot; are a series of conversations that development teams should have around building event-driven or other microservice based architectures. These topics will help teams determine which architectural patterns are best for them, and assist in building their systems and processes in a reliable and supportable way.&lt;/p&gt;
&lt;p&gt;The &amp;quot;Critical C&apos;s&amp;quot; are: &lt;strong&gt;Context&lt;/strong&gt;, &lt;strong&gt;Consistency&lt;/strong&gt;, &lt;strong&gt;Contract&lt;/strong&gt;, &lt;strong&gt;Chaos&lt;/strong&gt;, &lt;strong&gt;Competencies&lt;/strong&gt; and &lt;strong&gt;Coalescence&lt;/strong&gt;. Each of these topics will be covered in detail in this series of articles. Article 1 of the 6 was on the subject of &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-1of6-context.html&quot;&gt;Context&lt;/a&gt;. This is article 2 of the series, and covers the topic of &lt;strong&gt;Consistency&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;Consistency&lt;/h4&gt;
&lt;p&gt;The world is eventually consistent. The sooner we get that through our heads and start expecting our systems to act like it, the fewer problems, we will have. In fact, I&apos;ll go out on a limb and say that most of the problems in building and maintaining microservice architectures are the result of failing to fully embrace eventual consistency from the start.&lt;/p&gt;
&lt;p&gt;Data is consistent when it appears the same way when viewed from multiple perspectives. Our systems are said to be consistent when all of the data them is consistent. A system with strong consistency guarantees would be one where every actor, anywhere in the context of the application, would see the exact same value for any data element at any given time. A system that is &lt;em&gt;eventually consistent&lt;/em&gt; is one with strong guarantees that the data will reach all intended targets, but much weaker guarantees about how long it might take to achieve data consistency.&lt;/p&gt;
&lt;p&gt;Full consistency is impossible in a world where there is a finite speed of causation. Strong consistency can only be achieved when every portion of the application waits until the data is fully consistent before processing. This is generally quite difficult unless all of the data is housed in a single, ACID compliant data store, which of course, is a very bad idea when building scalable systems. &lt;strong&gt;Strong&lt;/strong&gt; consistency, or anything more stringent than &lt;strong&gt;eventual&lt;/strong&gt; consistency, may be appropriate under very specific circumstances when data stores are being geo-replicated (assuming the database server is designed for such a thing), but can cause real difficulties, especially in the areas of reliability and scalability, when attempted inside an application.&lt;/p&gt;
&lt;p&gt;We should challenge demands for higher levels of consistency with rigor. Attempts to provide stronger consistency guarantees than &lt;em&gt;eventual&lt;/em&gt; will cause far more problems than they are worth.&lt;/p&gt;
&lt;p&gt;We will always need to look for situations where consistency problems might occur (i.e. race-conditions), expect them to happen, and try to design our systems in such a way as to not need to worry about them. Race conditions and other consistency problems are smells. If you are in a situation where you are might see these types of problems, it may indicate that you need to reevaluate the details of your implementation.&lt;/p&gt;
&lt;p&gt;As an example, let&apos;s take a look at the 3 implementation diagrams below. In all 3 of these implementations, the goal is to have the WorkOrder service modify a WorkOrder and have the changes published onto a topic for downstream consumers. If a WorkOrder already exists, it needs to be loaded from the data store so that appropriate updates can be made. As you will see, the 3 implementations have very different reliability characteristics.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cognitiveinheritance.com/Images/CTP%20Pattern%20-%20Race%20Condition.png&quot; alt=&quot;3 Possible Implementations - Entity Updated and Published&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Implementation 1 - Dual-Write&lt;/strong&gt;: In the 1st example, the WorkOrder service attempts to both update the entity in the database, and publish the changes to the topic for downstream consumers. This is probably an attempt to keep both the event and the update consistent with one another, and is often mistaken for the simplest solution. However, since it is impossible to make more than 1 reliable change at a time, the only way this implementation can guarantee reliability is if the 1st update is done in an idempotent way. If that is the case, in the circumstances where the 2nd update fails, the service can roll the command message back onto the original topic and try the entire change again. Notice however that this doesn&apos;t guarantee consistency at all. If the DB is updated first, it may be done well before the publication ever occurs, since a retry would end up causing the publication to occur on a later attempt. Attempting to be clever and use a DB transaction to maintain consistency actually makes the problem worse for reasons that are outside of the scope of this discussion. Only a distributed transaction across the database and topic would accomplish that, and would do so at the expense of system scalability.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Implementation 2 - Race Condition&lt;/strong&gt;: In the 2nd example, the WorkOrder service reads data from the DB, and uses that to publish any needed updates to the topic. The topic is then used to feed the database, as well as any additional downstream consumers. While it might seem like the race-condition would be obvious here, it is not uncommon to miss this kind of systemic problem in a more complicated environment. It also can be tempting to build the system this way if the original implementation did not involve the DB. If we are adding the data store, we need to make sure data access happens prior to creating downstream events to avoid this kind of race condition. Stay vigilant for these types of scenarios and be willing to make the changes needed to protect the reliability of your system when requirements change.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Implementation 3 - Eventually Consistent&lt;/strong&gt;: In the 3rd example, the DB is used directly by both the WorkOrder service, and as the source of changes to the topic. This scenario is reliable but only &lt;strong&gt;eventually consistent&lt;/strong&gt;. That is, we know that both the DB and the topic will be updated since the WorkOrder service makes the DB update directly, and the reliable change feed from the DB instantiates a new execution context for the topic to be updated. This way, there is only a single change to system state made within each execution context, and we can know that they will happen reliably.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another example of a consistency smell might be when end-users insist that their UI should not return after they update something in an app, until the data is guaranteed to be consistent. I don&apos;t blame users for making these requests. After all, we trained them that the way to be sure that a system is reliable is to hit refresh until they see the data. In this situation, assuming we can&apos;t talk the users out of it, our best path is to make the UI wait until our polling, or a notification mechanism, identifies that the data is now consistent. I think this is a pretty rude thing to do to our users, but if they insist on it, I can only advise them against it. I will not destroy the scalability of systems I design, and add complexity to these systems that the developers will need to maintain forever, by simulating consistency deeper inside the app. The internals of the application should be considered eventually consistent at all times and we need to get used to thinking about our systems in this way.&lt;/p&gt;
&lt;h4&gt;Goals of the Conversation&lt;/h4&gt;
&lt;p&gt;Development teams should have conversations around &lt;strong&gt;Consistency&lt;/strong&gt; that are primarily focused around making certain that the system is assumed to be eventually consistency throughout. These conversations should include answering questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What patterns and tools will we use to create systems that support reliable, eventually consistent operations?&lt;/li&gt;
&lt;li&gt;How will we identify existing areas where higher-levels of consistency have been wedged-in and should be removed?&lt;/li&gt;
&lt;li&gt;How will we prevent future demands for higher-levels of consistency, either explicit or assumed, to creep in to our systems?&lt;/li&gt;
&lt;li&gt;How will we identify when there are unusual or unacceptable delays in the system reaching a consistent state?&lt;/li&gt;
&lt;li&gt;How will we communicate the status of the system and any delays in reaching a consistent state to the relevant stakeholders?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Next Up - Contract&lt;/h4&gt;
&lt;p&gt;In the next article of this series we will look at &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-3of6-contract.html&quot;&gt;Contract&lt;/a&gt; and how we can leverage contracts to make our systems more reliable while still maintaining our agility.&lt;/p&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-2of6-consistency.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/86685931-2951-4253-a923-563537481cee.html</guid>
  <pubDate>Mon, 19 Dec 2022 07:00:00 GMT</pubDate>
</item><item>
  <title>Teach Students how to Use ChatGPT</title>
  <description>&lt;p&gt;There have been a number of concerns raised, with clearly more to come, about the use of &lt;em&gt;ChatGPT&lt;/em&gt; and similar tools in academic circles. I am not an academic, but I am a professional and I believe these concerns to be misplaced.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As a professional in my field, I should and do use tools like &lt;em&gt;ChatGPT&lt;/em&gt; to do my job.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I, and the teams I work with, experiment with ways to use tools like ChatGPT better. We use these tools to create the foundation for our written work. We use them to automate the mundane stuff. We use them as thinking tools, to prompt us with ideas we might not have considered. This is not only allowed, it is encouraged!&lt;/p&gt;
&lt;h4&gt;Why should it be different for students?&lt;/h4&gt;
&lt;p&gt;There are several good analogs for &lt;em&gt;ChatGPT&lt;/em&gt; that we all have used for years, these include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The predictive text on our mobile phones - It is the same as pressing the middle word on the virtual keyboard to autocomplete a sentence. That is all this tool does, predict what is the most likely next word based on the inputs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The template in your chosen word processing software (i.e. MS Word or Google Docs) - Both will create a framework for you where you fill in the details. This is really all that &lt;em&gt;ChatGPT&lt;/em&gt; does, it just does it in a more visually impressive way.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Grammar and Thesaurus Software - &amp;quot;Suggests&amp;quot; words that can be modified to make the meaning clearer or the language more traditionally appropriate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Wikipedia, or other information aggregator - A source of text that can be used as a starting point for research, or a source of plagiarized material, at the discretion of the user.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Nobody thinks twice about using any of these tools anymore, though there was certainly concern early-on about Wikipedia. This is probably due to reasons like these:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;If anyone, student or professional, produced a work product that was just an unmodified template, it would considered very sloppy and incomplete work, and would be judged as such on its merits.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If anyone, student or professional, produced a work product that was copied from Wikipedia or other source, without significant modification or citation, there would be clear evidence of that fact available via the Internet.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;ChatGPT&lt;/em&gt; is concerning to academics because it has become good enough at doing the work of these template and predictive tools to pass a higher standard of review, and its use cannot be proven, only given a probability score. However, like all tools, the key is not &lt;strong&gt;that&lt;/strong&gt; it is used, but &lt;strong&gt;how&lt;/strong&gt; it is used.&lt;/p&gt;
&lt;p&gt;The text that &lt;em&gt;ChatGPT&lt;/em&gt; produces is generated probabilistically. It is not enough just to have it spit out a template and submit it as work product. Its facts need to be verified (and are often wrong). Its &amp;quot;analysis&amp;quot; needs to be tested and verified. Its &amp;quot;writing&amp;quot; needs to be clarified and organized. When you submit work where &lt;em&gt;ChatGPT&lt;/em&gt; was used to automate the mundane task of generating the basic layout, you are saying that you have verified the text and that you stand behind it. It is your work and you are approving it. &lt;strong&gt;If it has lied, you have lied. If the words it spit-out result in a bad analysis, it is your bad analysis&lt;/strong&gt;. The words are yours when you submit them regardless of whether they were generated via the neural network of your brain, the artificial neural network of &lt;em&gt;ChatGPT&lt;/em&gt;, or some other, perhaps procedural method.&lt;/p&gt;
&lt;p&gt;I&apos;ll say it clearly for emphasis:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;All work should be judged on its merits&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Educators should teach how to use these tools responsibly and safely&lt;/h4&gt;
&lt;p&gt;Academics and professionals alike, please do not attempt to legislate the use of these tools. Instead, focus on how they &lt;strong&gt;should be used&lt;/strong&gt;. Teach ethical and safe usage of these tools in a similar way to how we teach students to use Wikipedia. These productivity aids are not going away, they are only going to get better. We need to show everyone how to use them to their advantage, and to the advantage of their teams and of society.&lt;/p&gt;
&lt;p&gt;My field of &lt;em&gt;Software Engineering&lt;/em&gt; is primarily about solving problems. To solve problems, we describe solutions to these problems in ways that are easy for a machine to interpret. The only difference between the code I write that goes into a &lt;em&gt;compiler&lt;/em&gt; to be turned into machine-executable instructions, and the code I write to go into &lt;em&gt;ChatGPT&lt;/em&gt; is the language that I use to describe my intent. Using &lt;em&gt;ChatGPT&lt;/em&gt; is just writing a computer program using the English language rather than &lt;em&gt;C#&lt;/em&gt; or &lt;em&gt;Python&lt;/em&gt;. A process such as that should absolutely be encouraged whether the usage is academic or not.&lt;/p&gt;
&lt;p&gt;It is my firm belief that the handwringing about the productivity gains that a fantastic tool like ChatGPT can give us is not only misplaced, it is often dangerously misleading.&lt;/p&gt;
&lt;h4&gt;Addendum&lt;/h4&gt;
&lt;p&gt;I am only now realizing I should have used ChatGPT to produce the foundations of this text. A missed opportunity to be certain, though to be fair, I originally intended this to be a one or two liner, not an essay.&lt;/p&gt;
&lt;h4&gt;Disclosure&lt;/h4&gt;
&lt;p&gt;I have no stake whatsoever in ChatGPT except as a beta user.&lt;/p&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/teach-students-how-to-use-chatgpt.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/8ef8b660-1646-4b1b-91b8-e5cfdedad0b0.html</guid>
  <pubDate>Sat, 17 Dec 2022 16:00:00 GMT</pubDate>
</item><item>
  <title>The Critical C's of Microservices - Context</title>
  <description>&lt;p&gt;&amp;quot;&lt;strong&gt;The Critical C&apos;s of Microservices&lt;/strong&gt;&amp;quot; are a series of conversations that development teams should have around building event-driven or other microservice based architectures. These topics will help teams determine which architectural patterns are best for them, and assist in building their systems and processes in a reliable and supportable way.&lt;/p&gt;
&lt;p&gt;The &amp;quot;Critical C&apos;s&amp;quot; are: &lt;strong&gt;Context&lt;/strong&gt;, &lt;strong&gt;Consistency&lt;/strong&gt;, &lt;strong&gt;Contract&lt;/strong&gt;, &lt;strong&gt;Chaos&lt;/strong&gt;, &lt;strong&gt;Competencies&lt;/strong&gt; and &lt;strong&gt;Coalescence&lt;/strong&gt;. Each of these topics will be covered in detail in this series of articles, starting with &lt;strong&gt;Context&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Update: Part 2 of this series, &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-2of6-consistency.html&quot;&gt;Consistency&lt;/a&gt; is now available.&lt;/p&gt;
&lt;h3&gt;Context&lt;/h3&gt;
&lt;h4&gt;The Execution Context&lt;/h4&gt;
&lt;p&gt;The &lt;strong&gt;execution context&lt;/strong&gt; is the unit of work of all services. It represents the life-cycle of a single request, regardless of the details of how that request was received. So, whether an HTTP web request, or an asynchronous message from &lt;em&gt;Apache Kafka&lt;/em&gt; or &lt;em&gt;Azure Service Bus&lt;/em&gt;, the context we care about here is that of a single service processing that one message. Since, for reasons that will be discussed in a future article, there is no way to reliably make more than one change to system state within a single execution context, we must defend this context from the tendency to add additional state changes which would damage the reliability of our services.&lt;/p&gt;
&lt;p&gt;There are generally only two situations where it is ok to make more than one change to system state in a single execution context:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;When the first change is &lt;a href=&quot;https://en.wikipedia.org/wiki/Idempotence&quot; title=&quot;Idempotence is the ability to execute a task an arbitrary number of times (&amp;gt;1) and have the resulting state of the system be the same as if the task was executed once.&quot;&gt;idempotent&lt;/a&gt; so we can rollback the message and try again later without bad things happening due to duplication. An example of this is a database &lt;strong&gt;Upsert&lt;/strong&gt; where all of the data, including keys, is supplied. In this case, the 1st time we execute the request, we might insert the record in the DB. If a later change fails in the same context and we end up receiving the same message a 2nd time, the resulting update using the same data will leave the system in the same state as if the request was only executed once. Since this &lt;em&gt;idempotent&lt;/em&gt; operation can be executed as many times as necessary without impacting the ultimate state of the system, we can make other changes after this one and still rollback and retry the request if a subsequent operation fails, without damaging the system. Services that are &lt;em&gt;idempotent&lt;/em&gt; are much easier to orchestrate reliably, so much so that &lt;em&gt;idempotence&lt;/em&gt; is considered a highly-desireable feature of microservices.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When the second change is understood to be less-reliable. An example of this is logging. We don&apos;t want to fail a business-process due to failures in logging, so we accept that our logging, and certain other technical processes, may be less-reliable than our business processes. It is &lt;strong&gt;rarely&lt;/strong&gt; ok for a business process to be less-reliable in this way. Implementations that make certain business features less-reliable should be identified, documented, and discussed with an eye toward repaying what is likely to be technical debt.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Avoiding Dual-Writes&lt;/h4&gt;
&lt;p&gt;Ultimately, to maintain the reliability of our systems, we must be sure we are never trying to make more than one reliable change to system state in a single execution context. This is a very different way of thinking than most developers are used to. In fact, I would say it is the opposite of how many of us have been taught to think about these types of problems. Developers value simplicity, and rightfully so. Unfortunately, problems where we already have a service running that can host logic we need to add, make it &lt;strong&gt;seem like&lt;/strong&gt; the simplest solution is to just &amp;quot;add-on&amp;quot; the new logic to the existing code. The truth of the matter is far different. Let&apos;s look at an example:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cognitiveinheritance.com/Images/CTP%20Pattern%20-%20Never%20Add-On.png&quot; alt=&quot;Defend the Execution Context&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In these drawings we start with a RESTful service that updates a database and returns an appropriate response. This service makes only 1 change to system state so it can be built reliably.&lt;/p&gt;
&lt;p&gt;The next two drawings show ways of implementing a new requirement for the system to update a downstream dependency, say a Kafka topic, in addition to the database update. The default for many Technologists would be to just to add-on inside the service. That is, they might suggest that we should have the service update both the database and the topic as shown in the second drawing. This would be an example of the Dual-Writes Anti-Pattern and would hurt both system &lt;em&gt;reliability&lt;/em&gt; and &lt;em&gt;supportability&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Instead, the simplest solution that doesn&apos;t harm our system&apos;s reliability is actually to trigger the downstream action off of the DB update. That is, we can use the &lt;strong&gt;Outbox Pattern&lt;/strong&gt; or if the database supports it, &lt;strong&gt;Change Data Capture&lt;/strong&gt; or a &lt;strong&gt;Change Feed&lt;/strong&gt; to trigger a secondary process that produces the event message. Adding a deployment unit like this might make it feel like a more complicated solution, however it actually reduces the complexity of the initial service, avoids making a change to a working service, and will avoid creating reliability problems by not performing dual-writes.&lt;/p&gt;
&lt;p&gt;There are a few things to note here regarding atomic database transactions. An ACID-compliant update to a database represents a single change to system state. If we could make fully ACID-compliant changes across multiple data stores, or other boundaries like web services, the Dual-Writes Anti-Pattern would be much less of a problem. Unfortunately, distributed transactions cannot be used without severely impacting both scalability and performance and are not recommended. It should also be noted that, when talking about only 2 state changes, some threats to reliability may be reduced by being clever with our use of transactions. However, these tricks help us far less than one might think, and have severely diminishing returns when 3 or more state-changes are in-scope. Transactions, while good for keeping local data consistent, are not good for maintaining system reliability and are horrible for system scalability.&lt;/p&gt;
&lt;h4&gt;Goals of the Conversation&lt;/h4&gt;
&lt;p&gt;Development teams should have conversations around &lt;strong&gt;Context&lt;/strong&gt; that are primarily focused around the tools and techniques that they intend to use to avoid the Dual-Writes Anti-Pattern. These conversations should include answering questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What database technologies will we use and how can we leverage these tools to create downstream events based on changes to the database state?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Which of our services are currently idempotent and which ones could reasonably made so? How can we leverage our idempotent services to improve system reliability?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Do we have any services right now that contain business processes implemented in a less-reliable way? If so, pulling this functionality out into their own microservices might be a good starting point for decomposition.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What processes will we as a development team implement to track and manage the technical debt of having business processes implemented in a less-reliable way?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What processes will we implement to be sure that any future less-reliable implementations of business functionality are made with consideration and understanding of the debt being created and a plan to pay it off.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What processes will we implement to be sure that any existing or future less-reliable implementations of business functionality are documented, understood by, and prioritized by the business process owners.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Next Up - Consistency&lt;/h4&gt;
&lt;p&gt;In the next article of this series we will look at &lt;a href=&quot;https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-2of6-consistency.html&quot;&gt;Consistency&lt;/a&gt;, and see how &lt;strong&gt;Eventual Consistency&lt;/strong&gt; represents the reality of the world we live in.&lt;/p&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/critical-cs-of-microservices-1of6-context.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/082c3f8a-ac4a-4231-9962-01536167e4a5.html</guid>
  <pubDate>Mon, 12 Dec 2022 07:00:00 GMT</pubDate>
</item><item>
  <title>Social Media</title>
  <description>&lt;p&gt;The implosion of Twitter and my subsequent move to &lt;a href=&quot;https://fosstodon.org/@bsstahl&quot;&gt;the Fediverse&lt;/a&gt; has me reviewing all of my social media activity.&lt;/p&gt;
&lt;p&gt;A few of the things I&apos;ve looked at, and continue to investigate, include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How and why I use each platform&lt;/li&gt;
&lt;li&gt;How has my activity changed over time&lt;/li&gt;
&lt;li&gt;What previous statements I&apos;ve made should be corrected, amended, or otherwise revisited&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The revisiting of previous statements will likely happen either on the platform where they originated, or via microblog commentary &lt;a rel=&quot;me&quot; href=&quot;https://fosstodon.org/@Bsstahl&quot;&gt;@bsstahl@fosstodon.org&lt;/a&gt;. The rest of the analysis can be found here for everyone&apos;s benefit and comment. Of course, all comments, as indicated below, should be directed to my microblog &lt;a rel=&quot;me&quot; href=&quot;https://fosstodon.org/@Bsstahl&quot;&gt;@bsstahl@fosstodon.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My platforms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://cognitiveinheritance.com&quot;&gt;My Blog&lt;/a&gt;:
&lt;ul&gt;
&lt;li&gt;How I use it: Long form posts, usually technical in nature, that describe a concept or methodology.&lt;/li&gt;
&lt;li&gt;Future Plans: I hope to continue to use this platform for a long time and would like to be more active. However, I have said that many times and never been able to keep-up a good cadence.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Microblogging &lt;a href=&quot;https://fosstodon.org/@bsstahl&quot;&gt;@bsstahl@fosstodon.org&lt;/a&gt; but previously on Twitter:
&lt;ul&gt;
&lt;li&gt;How I use it:
&lt;ul&gt;
&lt;li&gt;Real-time communication about events such as tech conferences with other attendees&lt;/li&gt;
&lt;li&gt;Keeping in-touch with friends I met at events, usually without even having to directly interact&lt;/li&gt;
&lt;li&gt;Asking for input on concepts or ideas on how to do/use a tool or technology&lt;/li&gt;
&lt;li&gt;Asking for comments on my blog posts or presentations&lt;/li&gt;
&lt;li&gt;Promoting my or other speakers/writers posts or talks, especially when I attend a talk at a conference&lt;/li&gt;
&lt;li&gt;Publishing links to the code and slide-decks for my conference talks&lt;/li&gt;
&lt;li&gt;Publicly whining about problems with commercial products or services&lt;/li&gt;
&lt;li&gt;Making the occasional bad joke or snarky remark, usually at the expense of some celebrity, athlete or business&lt;/li&gt;
&lt;li&gt;Posting individual photos of people I know or places I go&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future Plans: With the move to the Fediverse, I may try to focus more completely on technology on this platform. Perhaps sports-related stuff should go elsewhere, maybe a photo-blog site like &lt;a href=&quot;https://pixelfed.org/&quot;&gt;PixelFed&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Facebook:
&lt;ul&gt;
&lt;li&gt;How I use it:
&lt;ul&gt;
&lt;li&gt;Private to only family members or friends I &lt;em&gt;actually know&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Posting Photos of family and friends to a limited audience&lt;/li&gt;
&lt;li&gt;Check-ins to places I&apos;m at for future reference, especially restaurants&lt;/li&gt;
&lt;li&gt;Posting political commentary and social memes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future Plans: I want a place for this that is not a walled-garden like Facebook. I feel like private communities could be run on &lt;a href=&quot;https://joinmastodon.org/&quot;&gt;Mastodon&lt;/a&gt; or other Fediverse servers like &lt;a href=&quot;https://pixelfed.org/&quot;&gt;PixelFed&lt;/a&gt;. There are a few possibilities I&apos;m exploring.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Flickr:
&lt;ul&gt;
&lt;li&gt;How I use it:
&lt;ul&gt;
&lt;li&gt;Paid &amp;quot;professional&amp;quot; account where I keep my off-site backup of every digital photo I&apos;ve ever taken, plus some scanned photos that were &amp;quot;born analog&amp;quot;, in full-size&lt;/li&gt;
&lt;li&gt;A public photostream of my favorite photos that are not family or friends&lt;/li&gt;
&lt;li&gt;A restricted (to family and friends) photostream of photos of family or friends&lt;/li&gt;
&lt;li&gt;Hosting of photos for my photoblog sites including &lt;a href=&quot;http://GiveEmHellDevils.com&quot;&gt;GiveEmHellDevils.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future Plans: Most of this will remain though I may syphon-off specific elements to other, more federated communities. For example, the restricted photostream could move to a &lt;a href=&quot;https://pixelfed.org/&quot;&gt;PixelFed&lt;/a&gt; server.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LinkedIn:
&lt;ul&gt;
&lt;li&gt;How I use it: A professional network of people I actually know in the technology space. I don&apos;t accept requests from people I have never met, including (especially?) recruiters. If I ever need to find a job again, it will be through referrals from people I know.&lt;/li&gt;
&lt;li&gt;Future Plans: I&apos;d like to do a better job of posting my appropriate content here, perhaps as links from my blog. Of course, that would require more posts on my blog (see above). Other than that, I don&apos;t expect any changes here.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;YouTube:
&lt;ul&gt;
&lt;li&gt;How I use it:
&lt;ul&gt;
&lt;li&gt;In the past, I used it to post videos of family and friends, though now those are usually posted privately via Flickr or Facebook&lt;/li&gt;
&lt;li&gt;Most of the time, I post videos of &lt;a href=&quot;https://www.youtube.com/playlist?list=PLCo2TFzFXPTQ5qIZTbbzFNcJL348fl6uO&quot;&gt;my technical presentations&lt;/a&gt;, or other presentations to the &lt;a href=&quot;https://www.youtube.com/playlist?list=PLCo2TFzFXPTQKUxyd61Rb9nN1d6jfEbAU&quot;&gt;local user groups&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future Plans: Continue to share videos of technical content&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Instagram
&lt;ul&gt;
&lt;li&gt;How I use it: To publish photos from my &lt;a href=&quot;http://GiveEmHellDevils.com&quot;&gt;GiveEmHellDevils.com&lt;/a&gt; photoblog.&lt;/li&gt;
&lt;li&gt;Future Plans: I would prefer to move this to a Fediverse service like &lt;a href=&quot;https://pixelfed.org/&quot;&gt;PixelFed&lt;/a&gt; that is not a walled-garden. I may start by adding a second stream using the Fediverse, and see what happens. If things go in the right direction, I may be able to eliminate Instagram.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GitHub:
&lt;ul&gt;
&lt;li&gt;How I use it:
&lt;ul&gt;
&lt;li&gt;A public repository of my Open-Source (FOSS) projects and code samples.&lt;/li&gt;
&lt;li&gt;A public repository of those FOSS projects that I contribute to via Pull-Request (PR)&lt;/li&gt;
&lt;li&gt;The hosting platform for my &lt;a href=&quot;https://cognitiveinheritance.com&quot;&gt;Blog Site&lt;/a&gt; and my &lt;a href=&quot;http://GiveEmHellDevils.com&quot;&gt;GiveEmHellDevils.com&lt;/a&gt; photoblog.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future Plans: No changes expected&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Azure DevOps
&lt;ul&gt;
&lt;li&gt;How I use it:
&lt;ul&gt;
&lt;li&gt;A private repository of my private code projects&lt;/li&gt;
&lt;li&gt;A private repository of the source material for my presentation slides&lt;/li&gt;
&lt;li&gt;A private repository of my many random experiments with code&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future Plans: No changes expected&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Azure Websites
&lt;ul&gt;
&lt;li&gt;How I use it:
&lt;ul&gt;
&lt;li&gt;To publish the individual slide-decks for my presentations as listed on &lt;a href=&quot;https://cognitiveinheritance.com/Pages/Speaking-Engagements.html&quot;&gt;my blog site&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future Plans: No changes expected&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TikTok
&lt;ul&gt;
&lt;li&gt;How I use it: I don&apos;t&lt;/li&gt;
&lt;li&gt;Future Plans: None&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/social-media.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/ba2df0f8-3f22-4ec2-97a8-3c3adc715ba4.html</guid>
  <pubDate>Fri, 11 Nov 2022 07:00:00 GMT</pubDate>
</item><item>
  <title>Identifying the Extraneous Publishing AntiPattern</title>
  <description>&lt;p&gt;What do you do when a dependency of one of your components needs data, ostensibly from your component, that your component doesn&apos;t actually need itself?&lt;/p&gt;
&lt;p&gt;Let&apos;s think about an example. Suppose our problem domain (the big black box in the drawings below) uses some data from 3 different data sources (labeled Source A, B &amp;amp; C in the drawings). There is also a downstream dependency that needs data from the problem domain, as well as from sources B &amp;amp; C. Some of the data required by the downstream dependency are not needed by, or owned by, the problem domain.&lt;/p&gt;
&lt;p&gt;There are 2 common implementations discussed now, and 1 slightly less obvious one discussed later in this article. We could:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pass-through the needed values on the output from our problem domain. This is the default option in many environments.&lt;/li&gt;
&lt;li&gt;Force the downstream to take additional dependencies on sources B &amp;amp; C&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note: In the worst of these cases, the data from one or more of these sources is not needed at all in the problem domain.&lt;/p&gt;
&lt;h2&gt;Option 1 - Increase Stamp Coupling&lt;/h2&gt;
&lt;p&gt;The most common choice is for the problem domain to publish all data that it is system of record for, as well as passing-through data needed by the downstream dependencies from the other sources. Since we know that a dependency needs the data, we simply provide it as part of the output of the problem domain system.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cognitiveinheritance.com/Images/Reducing Stamp Coupling - Coupled Data Feed - 800x314.png&quot; alt=&quot;Coupled Data Feed&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;Option 1 Advantages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The downstream systems only needs to take a dependency on a single data source.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Option 1 Disadvantages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Violates the Single Responsibility Principle because the problem domain may need to change for reasons the system doesn&apos;t care about. This can occur if a upstream producer adds or changes data, or a downstream consumer needs additional or changed data.&lt;/li&gt;
&lt;li&gt;The problem domain becomes the de-facto system of record for data it doesn&apos;t own. This may cause downstream consumers to be blocked by changes important to the consumers but not the problem domain. It also means that the provenance of the data is obscured from the consumer.&lt;/li&gt;
&lt;li&gt;Problems incurred by upstream data sources are exposed in the problem domain rather than in the dependent systems, irrespective of where the problem occurs or whether that problem actually impacts the problem domain. That is, the owners of the system in the problem domain become the &amp;quot;one neck to wring&amp;quot; for problems with the data, regardless of whether the problem is theirs, or they even care about that data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I refer to this option as an implementation of the &lt;strong&gt;Extraneous Publishing Antipattern&lt;/strong&gt; (Thanks to &lt;a href=&quot;https://twitter.com/jcnusz&quot;&gt;John Nusz&lt;/a&gt; for the naming suggestion). When this antipattern is used it will eventually cause significant problems for both the problem domain and its consumers as they evolve independently and the needs of each system change. The problem domain will be stuck with both their own requirements, and the requirements of their dependencies. The dependent systems meanwhile will be stuck waiting for changes in the upstream data provider. These changes will have no priority in that system because the changes are not needed in that domain and are not cared about by that product&apos;s ownership.&lt;/p&gt;
&lt;p&gt;The relationship between two components created by a shared data contract is known as &lt;strong&gt;stamp coupling&lt;/strong&gt;. Like any form of coupling, we should attempt to minimize it as much as possible between components so that we don&apos;t create hard dependencies that reduce our agility.&lt;/p&gt;
&lt;h2&gt;Option 2 - Multiplicative Dependencies&lt;/h2&gt;
&lt;p&gt;This option requires each downstream system to take a dependency on every system of record whose data it needs, regardless of what upstream data systems may already be utilizing that data source.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cognitiveinheritance.com/Images/Reducing Stamp Coupling - Direct Dependencies - 800x544.png&quot; alt=&quot;Direct Dependencies&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;Option 2 Advantages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Each system publishes only that information for which it is system of record, along with any necessary identifiers.&lt;/li&gt;
&lt;li&gt;Each dependency gets its data directly from the system of record without concern for intermediate actors.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Option 2 Disadvantages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A combinatorial explosion of dependencies is possible since each system has to take dependencies on every system it needs data from. In some cases, this means that the primary systems will have a huge number of dependencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While there is nothing inherently wrong with having a large number of repeated dependencies within the broader system, it can still cause difficulties in managing the various products when the dependency graph starts to get unwieldy. We&apos;ve seen similar problems in package-management and other dependency models before. However, there is a more common problem when we prematurely optimize our systems. If we optimize prematurely, we can create artifacts that we need to support forever, that create unnecessary complexity. As a result, I tend to use option 2 until the number of dependencies starts to grow. At that point, when the dependency graph starts to get out of control, we should look for another alternative.&lt;/p&gt;
&lt;h2&gt;Option 3 - Shared Aggregation Feed&lt;/h2&gt;
&lt;p&gt;Fortunately, there is a third option that may not be immediately apparent. We can get the best of both worlds, and limit the impact of the disadvantages described above, by moving the aggregation of the data to a separate system. In fact, depending on the technologies used, this aggregation may be able to be done using an infrastructure component that is a low-code solution less likely to have reliability concerns.&lt;/p&gt;
&lt;p&gt;In this option, each system publishes only the data for which it is system of record, as in option 1 above. However, instead of every system having to take a direct dependency on all of the upstream systems, a separate component is used to create a shared feed that represents the aggregation of the data from all of the sources.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cognitiveinheritance.com/Images/Reducing Stamp Coupling - Aggregated Data Feed - 800x276.png&quot; alt=&quot;Aggregated Data Feed&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;Option 3 Advantages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Each system publishes only that information for which it is system of record, along with any necessary identifiers.&lt;/li&gt;
&lt;li&gt;The downstream systems only needs to take a dependency on a single data source.&lt;/li&gt;
&lt;li&gt;A shared ownership can be arranged for the aggregation source that does not put the burden entirely on a single domain team.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Option 3 Disadvantages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The aggregation becomes the de-facto system of record for data it doesn&apos;t own, though that fact is anticipated and hopefully planned for. The ownership of this aggregation needs to be well-defined, potentially even shared among the teams that provide data for the aggregation. This still means though that the provenance of the data is obscured from the consumer.&lt;/li&gt;
&lt;li&gt;Problems incurred by upstream data sources are exposed in the aggregator rather than in the dependent systems, irrespective of where the problem occurs. That is, the owners of the aggregation system become the &amp;quot;one neck to wring&amp;quot; for problems with the data. However, as described above, that ownership can be shared among the teams that own the data sources.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It should be noted that in any case, regardless of implementation, a mechanism for correlating data across the feeds will be required. That is, the entity being described will need either a common identifier, or a way to translate the identifiers from one system to the others so that the system can match the data for the same entities appropriately.&lt;/p&gt;
&lt;p&gt;You&apos;ll notice that the aggregation system described in this option suffers from some of the same disadvantages as the other two options. The biggest difference however is that the sole purpose of this tool is to provide this aggregation. As a result, we handle all of these drawbacks in a domain that is entirely built for this purpose. Our business services remain focused on our business problems, and we create a special domain for the purpose of this data aggregation, with development processes that serve that purpose. In other words, we avoid expanding the definition of our problem domain to include the data aggregation as well. By maintaining each component&apos;s single responsibility in this way, we have the best chance of remaining agile, and not losing velocity due to extraneous concerns like unnecessary data dependencies.&lt;/p&gt;
&lt;h2&gt;Implementation&lt;/h2&gt;
&lt;p&gt;There are a number of ways we can perform the aggregation described in option 3.  Certain databases such as MongoDb and CosmosDb provide mechanisms that can be used to aggregate multiple data elements. There are also streaming data implementations which include tools for joining multiple streams, such as Apache Kafka&apos;s &lt;em&gt;kSQL&lt;/em&gt;. In future articles, I will explore some of these methods for minimizing stamp coupling and avoiding the Extraneous Publishing AntiPattern.&lt;/p&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/identifying-the-extraneous-publishing-antipattern.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/ea36d928-bb1c-4e06-95b0-de60a470c389.html</guid>
  <pubDate>Mon, 08 Aug 2022 23:30:00 GMT</pubDate>
</item><item>
  <title>Troubleshooting Information for Machinelearning-ModelBuilder Issue #1027</title>
  <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: The issue has been resolved. There was an old version of the Extension installed on failing systems that was causing problems with Visual Studio Extensions. Even though the version of the Extension showed as the correct one, an old version was being used. A reinstall of Visual Studio was needed to fix the problem.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There appears to be a problem with the &lt;em&gt;Preview&lt;/em&gt; version of the ModelBuilder tool for Visual Studio. This issue has been logged on &lt;a href=&quot;https://github.com/dotnet/machinelearning-modelbuilder/issues/1027&quot;&gt;GitHub&lt;/a&gt; and I am documenting my findings here in the hope that they will provide some insight into the problem. I will update this post when a solution or workaround is found.&lt;/p&gt;
&lt;p&gt;I want to be clear that this problem is in a &lt;strong&gt;preview version&lt;/strong&gt;, where problems like this are expected. I don&apos;t want the team working on this tooling to think that I am being reproachful of their work in any way. In fact, I want to compliment them and thank them for what is generally an extremely valuable tool.&lt;/p&gt;
&lt;p&gt;To reproduce this problem, use this &lt;a href=&quot;https://gist.githubusercontent.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/7466eb3f60fe881300de004954b240950069675d/SourceData_Mocked.csv&quot;&gt;Data File&lt;/a&gt; to train an &lt;strong&gt;Issue Classification&lt;/strong&gt; or &lt;strong&gt;Text Classification&lt;/strong&gt; model in the ModelBuilder tool by using the &lt;em&gt;Key&lt;/em&gt; column to predict the &lt;em&gt;Value&lt;/em&gt; column. The keys have intelligence built into them that are valid predictors of the Value (I didn&apos;t design this stuff).&lt;/p&gt;
&lt;p&gt;Machines that are unable to complete this task get a error stating &lt;code&gt;Specified label column &apos;Value&apos; was not found.&lt;/code&gt; with a stack trace similar to &lt;a href=&quot;https://gist.githubusercontent.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/52e01628cb6f449fd95091eaa033559a6c4b386e/StackTrace.txt&quot;&gt;this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This process seems to work fine on some machines and not on others. I have a machine that it works on, and one that it fails on, so I will attempt to document the differences here.&lt;/p&gt;
&lt;p&gt;The first thing I noticed is that the experience within the tool is &lt;em&gt;VERY DIFFERENT&lt;/em&gt; even though it is using the exact same version of the Model Builder.&lt;/p&gt;
&lt;h3&gt;From the machine that is able to train the model&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://gist.github.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/b73f673ab81247a529e419e56e1441b6b3cc099b/FunctionalMachine_ModelBuilder_Scenario.png&quot; alt=&quot;Scenarios - Functional Machine&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;From the machine having the failure&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://gist.github.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/b73f673ab81247a529e419e56e1441b6b3cc099b/ProblemMachine_ModelBuilder_Scenario.png&quot; alt=&quot;Scenarios - Failing Machine&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Everything seems to be different. The headline text, the options that can be chosen, and the graphics (or lack thereof). My first reaction when I saw this was to double-check that both machines are actually using the same version of the Model Builder tool.&lt;/p&gt;
&lt;h2&gt;Verifying the Version of the Tool&lt;/h2&gt;
&lt;p&gt;Spoiler alert: &lt;strong&gt;To the best I am able to verify, both machines are using the same version of the tool&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;From the machine that is able to train the model&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://gist.github.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/28226dc3fccf0155815f323a484146b7fc662305/FunctionalMachine_ModelBuilder_Version.png&quot; alt=&quot;ModelBuilder Tool Version - Functional Machine&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;From the machine having the failure&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://gist.github.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/28226dc3fccf0155815f323a484146b7fc662305/ProblemMachine_ModelBuilder_Version.png&quot; alt=&quot;ModelBuilder Tool Version - Failing Machine&quot; /&gt;&lt;/p&gt;
&lt;p&gt;My next thought is that I&apos;m not looking at the right thing. Perhaps, &lt;strong&gt;ML.NET Model Builder (Preview)&lt;/strong&gt; is not the correct Extension, or maybe the UI for this Extension is loaded separately from the Extension. I can&apos;t be sure, but I can&apos;t find anything that suggests this is really the case. Perhaps the dev team can give me some insight here.&lt;/p&gt;
&lt;h2&gt;Verifying the Region Settings of the Machine&lt;/h2&gt;
&lt;p&gt;While these versions are clearly the same, it is obvious from the graphics that the machines have different default date formats. Even though there are no dates in this data file, and both machines were using &lt;em&gt;US English&lt;/em&gt;, I changed the Region settings of the problem machine to match that of the functional machine. Predictably, this didn&apos;t solve the problem.&lt;/p&gt;
&lt;h3&gt;From the machine that is able to train the model&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://gist.github.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/28226dc3fccf0155815f323a484146b7fc662305/FunctionalMachine_Region.png&quot; alt=&quot;Region Settings - Functional Machine&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;From the machine having the failure - Original Settings&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://gist.github.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/28226dc3fccf0155815f323a484146b7fc662305/ProblemMachine_Region.png&quot; alt=&quot;Region Settings - Problem Machine&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;From the machine having the failure - Updated Settings&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://gist.github.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/28226dc3fccf0155815f323a484146b7fc662305/ProblemMachine_Region_Updated.png&quot; alt=&quot;Updated Region Settings - Problem Machine&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Checking the Versions of Visual Studio&lt;/h2&gt;
&lt;p&gt;The biggest difference between the two machines that I can think of, now that the region settings match, is the exact version &amp;amp; configuration of Visual Studio. Both machines have &lt;strong&gt;Visual Studio Enterprise 2019 Preview&lt;/strong&gt; versions, but the working machine has version &lt;em&gt;16.9.0 Preview 1.0&lt;/em&gt; while the failing machine uses version &lt;em&gt;16.10.0 Preview 1.0&lt;/em&gt;. You&apos;ll have to forgive me for not wanting to &amp;quot;upgrade&amp;quot; my working machine to the latest preview of Visual Studio, just in case that actually is the problem, though I suspect that is not the issue.&lt;/p&gt;
&lt;h3&gt;From the machine that is able to train the model&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://gist.github.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/7466eb3f60fe881300de004954b240950069675d/FunctionalMachine_VisualStudio.png&quot; alt=&quot;Visual Studio Version - Functional Machine&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;From the machine having the failure&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://gist.github.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/7466eb3f60fe881300de004954b240950069675d/ProblemMachine_VisualStudio.png&quot; alt=&quot;Visual Studio Version - Problem Machine&quot; /&gt;&lt;/p&gt;
&lt;p&gt;There are also differences in the installed payloads within Visual Studio between the 2 machines. Files containing information about the installations on each of the machines can be found below. These are the files produced when you click the &lt;em&gt;Copy Info&lt;/em&gt; button from the Visual Studio &lt;em&gt;About&lt;/em&gt; dialog.&lt;/p&gt;
&lt;h3&gt;From the machine that is able to train the model&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://gist.githubusercontent.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/7466eb3f60fe881300de004954b240950069675d/VisualStudioPayloads_FunctionalMachine.txt&quot;&gt;Visual Studio Payloads - Functional Machine&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;From the machine having the failure&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://gist.githubusercontent.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/7466eb3f60fe881300de004954b240950069675d/VisualStudioPayloads_ProblemMachine.txt&quot;&gt;Visual Studio Payloads - Problem Machine&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Windows Version&lt;/h2&gt;
&lt;p&gt;Another set of differences involve the machines themselves and the versions of Windows they are running. Both machines are running Windows 10, but the working machine runs a &lt;strong&gt;Pro&lt;/strong&gt; sku, while the problem machine uses an &lt;strong&gt;Enterprise&lt;/strong&gt; sku. Additionally, the machines have different specs, though they are consistent in that they are both underpowered for what I do. I&apos;m going to have to remedy that.&lt;/p&gt;
&lt;p&gt;I&apos;ve included some of the key information about the machines and their OS installations in the files below. None of it seems particularly probative to me.&lt;/p&gt;
&lt;h3&gt;From the machine that is able to train the model&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://gist.githubusercontent.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/c5148816444cca781a0ea428d5ed5a58bc6fc434/Windows_FunctionalMachine.txt&quot;&gt;System and OS - Functional Machine&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;From the machine having the failure&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://gist.githubusercontent.com/bsstahl/06db6cfce2fbbc2e6d455631ffff8108/raw/c5148816444cca781a0ea428d5ed5a58bc6fc434/Windows_ProblemMachine.txt&quot;&gt;System and OS - Problem Machine&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Other Things to Check&lt;/h2&gt;
&lt;p&gt;There are probably quite a number of additional differences I could look at between the 2 machines. Do you have any ideas about what else I could check to give the dev team the tools they need to solve this problem?&lt;/p&gt;
</description>
  <link>https://www.cognitiveinheritance.com/Posts/Troubleshooting-Machine-Learning-ModelBuilder-Issue-1027.html</link>
  <author>aa88801d-9543-467e-9d7e-8768d2d14aa7@bsstahl.com (Barry S. Stahl)</author>
  <guid>https://www.cognitiveinheritance.com/Permalinks/f7d71577-57c3-4676-a5fa-2745a2bb8cf7.html</guid>
  <pubDate>Sat, 03 Apr 2021 18:00:00 GMT</pubDate>
</item>
</channel>
</rss>